{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 1\n",
    "\n",
    "##### Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Market\", \"Constant\", \"Price\", \"EngineSize\", \"SportsBike\", \"Brand2\", \"Brand3\", \"z1\", \"z2\", \"z3\", \"z4\", \"shares\"]\n"
     ]
    }
   ],
   "source": [
    "# Set working directory\n",
    "dir = \"/Users/JoshuaHigbee/Box/2. Second Year/2. Winter Quarter - 2021/\" *\n",
    "      \"Industrial Organization II - Hortacsu/Problem Sets/Problem Set 1/\";\n",
    "cd(dir);\n",
    "\n",
    "# Load packages\n",
    "using CSV, DataFrames, Random, Distributions, LinearAlgebra,\n",
    "      LatexPrint, StatsBase, Plots, SpecialFunctions\n",
    "using Optim, ForwardDiff, PyCall\n",
    "\n",
    "# Set seed\n",
    "Random.seed!(12345);\n",
    "\n",
    "# Read in data\n",
    "data = CSV.read(\"psetOne.csv\", DataFrame);\n",
    "println(names(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "\n",
    "##### Load data for market $t=17$, and set up parameter values (coefficient order is Price, Constant, Engine CC, BikeType, Brand2, Brand3) and $\\xi$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data \n",
    "d17 = data[data.Market .== 17, :];\n",
    "\n",
    "# Parameters\n",
    "θ_given =  [-3.0 1.0 1.0 2.0 -1.0 1.0]'\n",
    "α = θ_given[1]\n",
    "\n",
    "# Ownership matrix\n",
    "d17.Brand1 = Ref(1.0) .- max.(d17.Brand2, d17.Brand3);\n",
    "Δ = (d17.Brand1 .* d17.Brand1') .+ (d17.Brand2 .* d17.Brand2') .+ (d17.Brand3 .* d17.Brand3')\n",
    "\n",
    "# ξ values\n",
    "ξ_rand = rand(Normal(0,1),7);\n",
    "ξ_newton = ξ_rand; # ξ_simple\n",
    "ξ_newton = zeros(7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define useful functions for solving fixed point pricing equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newton_fxp (generic function with 1 method)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shares function\n",
    "function s_newton(price)\n",
    "    X = hcat(price, d17.Constant, d17.EngineSize, d17.SportsBike, d17.Brand2, d17.Brand3)\n",
    "    exp_term = X * θ_given .+ ξ_newton\n",
    "    max_exp = maximum(exp_term)\n",
    "    num = exp.(exp_term .- max_exp)\n",
    "    return num / (exp(-max_exp) + sum(num))\n",
    "end\n",
    "\n",
    "\n",
    "# Jacobian of shares function\n",
    "function s_Jac_newton(price)\n",
    "    s = s_newton(price)\n",
    "    return - α * ((s * s') .- diagm(vec(s))) # α is negative in this setting\n",
    "end\n",
    "\n",
    "\n",
    "# Hessian of shares function\n",
    "function s_Hess_newton(price)\n",
    "    s = s_newton(price)\n",
    "    Hess = Array{Float64}(undef, 7, 7, 7)\n",
    "    for j in 1:7\n",
    "        for k in 1:7\n",
    "            for l in 1:7\n",
    "                Hess[j,k,l] = α^2 *\n",
    "                      ((2*s[j]*s[k]*s[l] - 3*s[j]*s[k] + s[j])*(j==k && j==l) +\n",
    "                      (2*s[j]*s[k]*s[l] - s[j]*s[l])*(j==k && j!=l) +\n",
    "                      (2*s[j]*s[k]*s[l] - s[k]*s[l])*(j!=k && j==l) +\n",
    "                      (2*s[j]*s[k]*s[l] - s[j]*s[k])*(j!=k && k==l) +\n",
    "                      (2*s[j]*s[k]*s[l])*(l!=k && k!=j && j!=l))\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return Hess\n",
    "end\n",
    "\n",
    "\n",
    "# Function for Newton's method (using p + Ω^{-1} * s = 0)\n",
    "function f_newton(price)\n",
    "    s = s_newton(price)\n",
    "    s_J = s_Jac_newton(price)\n",
    "    Ω = Δ .* s_J\n",
    "    f = price + inv(Ω) * s\n",
    "    return f\n",
    "end\n",
    "\n",
    "\n",
    "# Jacobian of Ω^{-1} (for use in computing Jacobian of function for fxp est)\n",
    "function Ω_inv_Jac_newton(price)\n",
    "    s = s_newton(price)\n",
    "    s_J = s_Jac_newton(price)\n",
    "    s_H = s_Hess_newton(price)\n",
    "    Ω = Δ .* s_J\n",
    "    Ω_J = Δ .* s_H\n",
    "\n",
    "    Ω_J_inv = Array{Float64}(undef, length(s), length(s), length(s))\n",
    "    for j in 1:length(s)\n",
    "        Ω_J_inv[:,:,j] = - inv(Ω) * Ω_J[:,:,j] * inv(Ω)\n",
    "    end\n",
    "    return Ω_J_inv\n",
    "end\n",
    "\n",
    "\n",
    "# Jacobian of function for Newton's method\n",
    "function f_newton_J(price)\n",
    "    s = s_newton(price)\n",
    "    s_J = s_Jac_newton(price)\n",
    "    Ω = Δ .* s_J\n",
    "    Ω_inv_J = Ω_inv_Jac_newton(price)\n",
    "    Ω_inv_J_times_s = Matrix(0.0 * I, length(s), length(s))\n",
    "    for j in 1:length(s)\n",
    "        Ω_inv_J_times_s[:,j] = Ω_inv_J[:,:,j] * s\n",
    "    end\n",
    "    ∇f_newton = I + Ω_inv_J_times_s + inv(Ω) * s_J\n",
    "    return ∇f_newton\n",
    "end\n",
    "\n",
    "\n",
    "# Actually estimate the fixed point\n",
    "function newton_fxp(price, ϵ)\n",
    "    diff = 1\n",
    "    p_0 = price\n",
    "    iter=1\n",
    "    while diff > ϵ\n",
    "        # Solve equation\n",
    "        fxp = f_newton(p_0)\n",
    "        ∇fxp = f_newton_J(p_0)\n",
    "        # ∇fxp = ForwardDiff.jacobian(f_newton, p_0)\n",
    "        p_1 = p_0 - inv(∇fxp) * fxp\n",
    "\n",
    "        # Update values and loop\n",
    "        diff = maximum(abs.(p_1 .- p_0))\n",
    "        println(\"Iteration \" * string(iter) * \"     Difference \" * string(diff))\n",
    "        p_0 = p_1\n",
    "        iter = iter + 1\n",
    "    end\n",
    "    return p_0\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solve fixed point equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1     Difference 2.484826536163365\n",
      "Iteration 2     Difference 0.2893243176990721\n",
      "Iteration 3     Difference 0.0726965625358531\n",
      "Iteration 4     Difference 0.006524393561025077\n",
      "Iteration 5     Difference 4.2079754713597595e-5\n",
      "Iteration 6     Difference 1.679278494037817e-9\n",
      "Iteration 7     Difference 6.661338147750939e-16\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7×1 Array{Float64,2}:\n",
       " 0.38447413297903904\n",
       " 0.3844741329790391\n",
       " 0.3523194580438232\n",
       " 0.3523194580438232\n",
       " 1.7822602606218438\n",
       " 1.782260260621844\n",
       " 1.782260260621844"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_init = ones(7);\n",
    "p_init = d17.Price;\n",
    "p_optimal = newton_fxp(p_init, 1.0e-10)\n",
    "\n",
    "println(\" \")\n",
    "p_optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check to ensure it is a fixed point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7×1 Array{Float64,2}:\n",
      " -1.1102230246251565e-16\n",
      "  0.0\n",
      "  0.0\n",
      " -5.551115123125783e-17\n",
      "  3.9968028886505635e-15\n",
      "  3.9968028886505635e-15\n",
      "  3.3306690738754696e-15"
     ]
    }
   ],
   "source": [
    "f_newton(p_optimal)\n",
    "show(stdout, \"text/plain\", f_newton(p_optimal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "\n",
    "##### Write share prediction functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sHat_from_ŝ (generic function with 1 method)"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Individual share predictor function (given mean utilities)\n",
    "# function sHat_ind(;δ, X=0.0, σ, ζ=0.0, I_n=1)\n",
    "    \n",
    "#     # Fill values if unspecified (default)\n",
    "#     if X == 0.0\n",
    "#         X = repeat(fill(0.0,length(σ))', length(δ))\n",
    "#     end\n",
    "#     if ζ == 0.0\n",
    "#         ζ = reshape(fill(0.0,length(σ)*I_n), I_n, length(σ))\n",
    "#     end\n",
    "\n",
    "#     # Construct numerators\n",
    "#     const_term = repeat(δ', outer=I_n)\n",
    "#     rc_term = ζ * (X .* repeat(σ, outer=length(δ)))'\n",
    "#     exp_term = const_term .+ rc_term\n",
    "#     max_exp = maximum(exp_term, dims=2)\n",
    "#     num = exp.(exp_term - repeat(max_exp, inner=(1,length(δ))))\n",
    "\n",
    "#     # Construct denominators and shares\n",
    "#     denom = repeat(exp.(-max_exp) .+ sum(num, dims=2), inner=(1,length(δ)))\n",
    "#     ŝ_i = num ./ denom\n",
    "#     return ŝ_i\n",
    "# end\n",
    "\n",
    "# Individual share predictor function (given mean utilities)\n",
    "function sHat_ind(;δ, X=0.0, σ, ζ=0.0, I_n=1)\n",
    "    \n",
    "    # Fill values if unspecified (default)\n",
    "    if X == 0.0\n",
    "        X = repeat(fill(0.0,length(σ))', length(δ))\n",
    "    end\n",
    "    if ζ == 0.0\n",
    "        ζ = reshape(fill(0.0,length(σ)*I_n), I_n, length(σ))\n",
    "    end\n",
    "\n",
    "    # Construct numerators\n",
    "    const_term = repeat(δ', outer=I_n)\n",
    "    rc_term = ζ * (X .* repeat(σ, outer=length(δ)))'\n",
    "    exp_term = const_term .+ rc_term\n",
    "    num = exp.(exp_term)\n",
    "\n",
    "    # Construct denominators and shares\n",
    "    denom = repeat(Ref(1.0) .+ sum(num, dims=2), inner=(1,length(δ)))\n",
    "    ŝ_i = num ./ denom\n",
    "    return ŝ_i\n",
    "end\n",
    "\n",
    "# Share predictor function (for heterogeneity)\n",
    "function sHat(;δ, X=0.0, σ, ζ=0.0, I_n=1)\n",
    "    ŝ_i = sHat_ind(δ=δ, X=X, σ=σ, ζ=ζ, I_n=I_n)\n",
    "    ŝ = 1/(I_n) * sum(ŝ_i, dims=1)\n",
    "    return vec(ŝ)\n",
    "end\n",
    "\n",
    "# Share predictor function for taking ŝ after it's already computed\n",
    "function sHat_from_ŝ(; ŝ_i, I_n=1)\n",
    "    ŝ = 1/(I_n) * sum(ŝ_i, dims=1)\n",
    "    return vec(ŝ)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set up parameters and data for test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_q9 = [3, 3, 3];\n",
    "δ_q9 = [zeros(J_q9[1]), [40, 20, 20], zeros(J_q9[3])];\n",
    "σ_q9 = [[0.0], [0.0], [0.1]];\n",
    "X_q9 = [[], [], [repeat([1.0], 3), [1.0; 3.0; -1.0], [10.0; 10.0; -3.0]]];\n",
    "I_q9 = [[], [], 50];\n",
    "ζ_q9 = [[], [], reshape(rand(Normal(0,1),length(σ_q9[3])*I_q9[3]), I_q9[3], length(σ_q9[3]))];\n",
    "shares_q9 = [];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test all cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25, 0.25, 0.25]\n"
     ]
    }
   ],
   "source": [
    "# First case\n",
    "s_test = sHat(δ=δ_q9[1], σ=σ_q9[1]);\n",
    "println(s_test);\n",
    "sum(s_test, dims=2)[1]\n",
    "push!(shares_q9, s_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9999999958776928, 2.0611536139418496e-9, 2.0611536139418496e-9]\n"
     ]
    }
   ],
   "source": [
    "# Second case\n",
    "s_test = sHat(δ=δ_q9[2], σ=σ_q9[2]);\n",
    "println(s_test);\n",
    "sum(s_test, dims=2)[1]\n",
    "push!(shares_q9, s_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2493036, 0.2493036, 0.2493036]\n",
      "[0.2473595, 0.2477251, 0.2548299]\n",
      "[0.2385902, 0.2385902, 0.2792201]\n"
     ]
    }
   ],
   "source": [
    "# Third case\n",
    "s_test = sHat(δ=δ_q9[3], X=X_q9[3][1], σ=σ_q9[3], ζ=ζ_q9[3], I_n=I_q9[3])\n",
    "println(convert.(Float64,round.(s_test, digits=7)))\n",
    "push!(shares_q9, s_test);\n",
    "\n",
    "s_test = sHat(δ=δ_q9[3], X=X_q9[3][2], σ=σ_q9[3], ζ=ζ_q9[3], I_n=I_q9[3])\n",
    "println(convert.(Float64,round.(s_test, digits=7)))\n",
    "push!(shares_q9, s_test);\n",
    "\n",
    "s_test = sHat(δ=δ_q9[3], X=X_q9[3][3], σ=σ_q9[3], ζ=ζ_q9[3], I_n=I_q9[3])\n",
    "println(convert.(Float64,round.(s_test, digits=7)))\n",
    "push!(shares_q9, s_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10 - - - - - - - - - CURRENTLY HAS TWO CONTRACTION MAPPING FUNCTIONS\n",
    "\n",
    "##### Create functions for share inversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "invert_s (generic function with 1 method)"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Contraction mapping function\n",
    "# function s_contraction_map(;s, X, I_n, σ, ζ, J, L̄=1.0-1.0e-7, output=false)\n",
    "#       δ_0 = convert.(Real, zeros(length(s)))\n",
    "#       L = 0.5 # Initialize contraction mapping ratio\n",
    "#       iter = 0 # Initialize iteration count\n",
    "#       δ_diff = 0.5 # Initialize difference in δ (in case L misbehaves)\n",
    "#       δ_diff_h = Array{Real}(undef, 1, 3)\n",
    "#       while (δ_diff > 1.0e-7) && (L < L̄)\n",
    "#             # Numerical inversion\n",
    "#             δ_1 = δ_0 .+ log.(s) .- log.(sHat(δ=δ_0, X=X, σ=σ, ζ=ζ, I_n=I_n))\n",
    "\n",
    "#             # Max distance in δ\n",
    "#             δ_diff = maximum(abs.(δ_1 - δ_0))\n",
    "\n",
    "#             # Track iterations and update Lipschitz constant every 50 iters\n",
    "#             iter = iter + 1\n",
    "#             if ((iter + 2) % 50) == 0\n",
    "#                   δ_diff_h[1] = Real(δ_diff)\n",
    "#             end\n",
    "#             if ((iter + 1) % 50) == 0\n",
    "#                   δ_diff_h[2] = Real(δ_diff)\n",
    "#             end\n",
    "#             if (iter % 50) == 0\n",
    "#                   δ_diff_h[3] = Real(δ_diff)\n",
    "#                   L = (δ_diff_h[2]^2) / (δ_diff_h[3] * δ_diff_h[1])\n",
    "#                   if output==true\n",
    "#                         println(\"Iteration  \" * string(iter) *\n",
    "#                               \"    Contraction term L is \" * string(L))\n",
    "#                   end\n",
    "#             end\n",
    "#             δ_0 = δ_1\n",
    "#       end\n",
    "\n",
    "#       return δ_0\n",
    "# end\n",
    "\n",
    "\n",
    "# Contraction mapping function\n",
    "function s_contraction_map(;s, X, I_n, σ, ζ, J, ϵ_contract = 1.0e-5, output=false)\n",
    "      δ_0 = convert.(Real, zeros(length(s)))\n",
    "      iter = 0 # Initialize iteration count\n",
    "      δ_diff = 0.5 # Initialize difference in δ (in case L misbehaves)\n",
    "      δ_diff_h = Array{Real}(undef, 1, 3)\n",
    "      while (δ_diff > ϵ_contract) \n",
    "            # Numerical inversion\n",
    "            δ_1 = δ_0 .+ log.(s) .- log.(sHat(δ=δ_0, X=X, σ=σ, ζ=ζ, I_n=I_n))\n",
    "\n",
    "            # Max distance in δ\n",
    "            δ_diff = maximum(abs.(δ_1 - δ_0))\n",
    "\n",
    "            if (iter % 50) == 0 && output==true\n",
    "                println(\"Iteration  \" * string(iter) * \"    Difference is \" * string(δ_diff))\n",
    "            end\n",
    "            δ_0 = δ_1\n",
    "      end\n",
    "\n",
    "      return δ_0\n",
    "end\n",
    "\n",
    "\n",
    "# Log shares Jacobian function - vectorized\n",
    "function log_s_Jac(; ŝ_i, I_n=1, J)\n",
    "      ∫ŝ_j_mat = repeat(1/(I_n) .* sum(ŝ_i, dims=1), outer=J)'\n",
    "      own_term = 1.0/(I_n) * ŝ_i' * (Ref(1.0) .- ŝ_i) .* Matrix(I, J, J)\n",
    "      cross_term = -1.0/(I_n) * (ŝ_i' * ŝ_i) .* (Ref(1.0) .- Matrix(I, J, J))\n",
    "      return (own_term .+ cross_term) ./ ∫ŝ_j_mat\n",
    "end\n",
    "\n",
    "\n",
    "# Newton's method function\n",
    "function s_newton_fxp(; s, δ_0, X, I_n, σ, ζ, J, ϵ_conv=1.0e-14, output=false, maxiter = 1e5)\n",
    "    diff = 0.5\n",
    "    iter = 0 # Initialize iteration count\n",
    "    while diff > ϵ_conv && iter < maxiter\n",
    "        # Compute\n",
    "        ŝ_i = sHat_ind(δ=δ_0, X=X, σ=σ, ζ=ζ, I_n=I_n)\n",
    "        ŝ = sHat_from_ŝ(ŝ_i=ŝ_i, I_n=I_n)\n",
    "        log_sJ = log_s_Jac(ŝ_i=ŝ_i, I_n=I_n, J=J)\n",
    "        log_s = log.(ŝ)\n",
    "        δ_1 = δ_0 .- inv(log_sJ) * (log_s - log.(s))\n",
    "\n",
    "        # Check difference and iterate\n",
    "        diff = maximum(abs.(δ_1 .- δ_0))\n",
    "        iter = iter + 1\n",
    "        if output==true\n",
    "              println(\"Iteration  \" * string(iter) *\n",
    "                    \"    Difference is \" * string(diff))\n",
    "        end\n",
    "        δ_0 = δ_1\n",
    "    end\n",
    "\n",
    "    return δ_0\n",
    "end\n",
    "\n",
    "\n",
    "# Combine two methods function\n",
    "function invert_s(; s, X, I_n, σ, ζ, J, ϵ_contract=1.0e-5, ϵ_conv=1.0e-14, output=false, maxiter_newton = 1e5)\n",
    "    δ_contraction = s_contraction_map(s=s, X=X, I_n=I_n, σ=σ, ζ=ζ, J=J, ϵ_contract=ϵ_contract, output=output)\n",
    "    δ = s_newton_fxp(s=s, δ_0=δ_contraction, X=X, I_n=I_n, σ=σ, ζ=ζ, J=J, ϵ_conv=ϵ_conv, output=output, \n",
    "            maxiter = maxiter_newton)\n",
    "    return δ\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test functions with data from market 17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_17 = 25;\n",
    "X_17 = convert(Matrix, hcat(d17[:, [:Price, :Constant, :EngineSize, :SportsBike, :Brand2, :Brand3]]));\n",
    "Z_17 = convert(Matrix, hcat(d17[:, [:z1, :z2, :z3, :z4]]));\n",
    "σ_17 = zeros(size(X_17)[2])';\n",
    "ζ_17 = reshape(rand(Normal(0,1),length(σ_17)*I_17), I_17, length(σ_17));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7-element Array{Float64,1}:\n",
       "  2.0697845385676574\n",
       " -0.3439439517828262\n",
       " -2.9273567831528453\n",
       "  0.6068451864947533\n",
       "  3.141160653013621\n",
       "  1.3883038447921399\n",
       "  2.3472954727255972"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test contraction\n",
    "δ_contract = s_contraction_map(s=d17.shares, X=X_17, I_n=I_17, σ=σ_17, ζ=ζ_17, J=size(X_17)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7-element Array{Float64,1}:\n",
       "  2.070264979033944\n",
       " -0.34346351131653924\n",
       " -2.9268763426865583\n",
       "  0.6073256269610395\n",
       "  3.1416410934799073\n",
       "  1.3887842852584265\n",
       "  2.3477759131918825"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Newton's method\n",
    "s_newton_fxp(s=d17.shares, δ_0 = δ_contract, X=X_17, I_n=I_17, σ=σ_17, ζ=ζ_17, J=size(X_17)[1], ϵ_conv=1.0e-14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTRACTION EPSILON IS LARGE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7-element Array{Float64,1}:\n",
       "  2.070264979033939\n",
       " -0.34346351131654446\n",
       " -2.926876342686563\n",
       "  0.6073256269610349\n",
       "  3.1416410934799024\n",
       "  1.3887842852584218\n",
       "  2.347775913191879"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test both\n",
    "invert_s(s=d17.shares, X=X_17, I_n=I_17, σ=σ_17, ζ=ζ_17, J=size(X_17)[1], ϵ_contract=1.0e-4, ϵ_conv=1.0e-14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test with data from the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0]\n",
      "[38.46485052094403, 18.464850520944033, 18.464850520944033]\n",
      "[0.0, 0.0, 0.0]\n",
      "[-5.6237498747096835e-5, -0.0013437516242858919, -0.030001976338485375]\n",
      "[0.030934542812276183, 0.030934542812276183, -0.15380302015376077]\n"
     ]
    }
   ],
   "source": [
    "println(invert_s(s=shares_q9[1], σ=σ_q9[2], X=0.0, I_n=1, ζ=0.0, J=J_q9[1]))\n",
    "println(invert_s(s=shares_q9[2], σ=σ_q9[2], X=0.0, I_n=1, ζ=0.0, J=J_q9[2], ϵ_contract=1.0e-4))\n",
    "println(invert_s(s=shares_q9[3], σ=σ_q9[3], X=X_q9[3][1], I_n=I_q9[3], ζ=ζ_q9[3], J=J_q9[3]))\n",
    "println(invert_s(s=shares_q9[3], σ=σ_q9[3], X=X_q9[3][2], I_n=I_q9[3], ζ=ζ_q9[3], J=J_q9[3]))\n",
    "println(invert_s(s=shares_q9[3], σ=σ_q9[3], X=X_q9[3][3], I_n=I_q9[3], ζ=ζ_q9[3], J=J_q9[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11\n",
    "\n",
    "##### Write function for computing $\\xi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ξ_rclogit (generic function with 1 method)"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implicit function for ξ - all markets (X_all is vector of matrices)\n",
    "function ξ_rclogit(; X_all, θ, s_all, ζ=0.0, I_num=1, maxiter_newton=1e5, rclogit_output=false)\n",
    "    # θ split between linear terms (1) and nonlinear terms (2)\n",
    "    αβ = θ[1] # Put price first for consistency\n",
    "    σ = θ[2]\n",
    "    \n",
    "    # Loop through markets and invert shares\n",
    "    δhat_all = []\n",
    "    for mkt in 1:length(X_all)\n",
    "        if rclogit_output==true\n",
    "            println(\"Market number is \" * string(mkt) * \" of \" * string(length(X_all)))\n",
    "        end\n",
    "        δhat = invert_s(s=s_all[mkt], X=X_all[mkt], I_n=I_num, σ=σ, ζ=ζ, J=length(s_all[mkt]), \n",
    "                    ϵ_contract=1.0e-3, ϵ_conv=1.0e-14, maxiter_newton = maxiter_newton)\n",
    "        push!(δhat_all, δhat)\n",
    "    end\n",
    "    \n",
    "    # Stack data and compute δ_mean\n",
    "    δhat = reduce(vcat, δhat_all)\n",
    "    X_stack = reduce(vcat, X_all)\n",
    "    δ_mean = X_stack * αβ\n",
    "\n",
    "    # Subtract off mean utility to get ξ̂\n",
    "    return δhat .- δ_mean\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write function for splicing data into markets (array of matrices and vectors, for shares and variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mkt_X_s_break (generic function with 1 method)"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mkt_X_s_break(; exclude_vec)\n",
    "    X_full_mkt = []\n",
    "    s_full_mkt = []\n",
    "    for mkt in unique(data[[x ∉ exclude_vec for x in data.Market], :Market])\n",
    "        X_mkt = convert(Matrix, data[data.Market .== mkt,\n",
    "                    [:Price, :Constant, :EngineSize, :SportsBike, :Brand2, :Brand3]])\n",
    "        push!(X_full_mkt, X_mkt)\n",
    "        \n",
    "        s_mkt = data[data.Market .== mkt, :shares]\n",
    "        push!(s_full_mkt, s_mkt)\n",
    "    end\n",
    "    return [X_full_mkt, s_full_mkt]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test functions with data from market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test parameters\n",
    "I_test = 25\n",
    "σ_test = zeros(6)\n",
    "ζ_test = reshape(rand(Normal(0,1),length(σ_test)*I_test), I_test, length(σ_test))\n",
    "Z_test = convert(Matrix, data[:, [:z1, :z2, :z3, :z4]])\n",
    "W_test = inv(Z_test' * Z_test);\n",
    "\n",
    "# Choose data\n",
    "test_data = mkt_X_s_break(exclude_vec = []);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23.215982 seconds (137.72 M allocations: 20.945 GiB, 21.66% gc time)\n"
     ]
    }
   ],
   "source": [
    "# Test functions at θ = 0\n",
    "θ_zeros = [zeros(6), zeros(6)']\n",
    "@time ξ_zeros = ξ_rclogit(X_all=test_data[1], θ=θ_test, s_all=test_data[2], ζ=ζ_test, I_num=I_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Array{Float64,1}:\n",
       "  3.4175577069186134\n",
       "  2.219989832335631\n",
       " -2.834820623687745\n",
       "  4.317272874619497\n",
       "  1.4596209841341568\n",
       "  1.0254328494996454\n",
       "  1.5368650848736907\n",
       " -2.7318744786927485"
      ]
     },
     "execution_count": 733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ξ_zeros[1:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write GMM objective function using implicit function $\\xi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252.5932803130469"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function f_gmm_rclogit_implθ(; W=I, Z, X_all, θ, s_all, ζ, I_num)\n",
    "    ξ = ξ_rclogit(X_all=X_all, θ=θ, s_all=s_all, ζ=ζ, I_num=I_num)\n",
    "    return (Z' * ξ)' * W * (Z' * ξ)\n",
    "end\n",
    "\n",
    "# Test objective function - computing ξ within\n",
    "f_gmm_rclogit_implθ(W=W_test, Z=Z_test, X_all=test_data[1], θ=[zeros(6), zeros(6)'], s_all=test_data[2], \n",
    "    ζ=ζ_test, I_num=I_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rewrite objective function as a function of only $\\sigma$ (no linear terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f_gmm_rclogit_σ (generic function with 1 method)"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for computing linear parameters\n",
    "function θ_tsls(; X, Z, W, δ)\n",
    "    B = X' * Z * W * Z'\n",
    "    return inv(B * X) * (B * δ)\n",
    "end\n",
    "\n",
    "\n",
    "# Function returning ξ(σ), δ(σ), and θ̄(σ)\n",
    "function ξδθ_σ_rclogit(; X_all, σ, s_all, ζ=0.0, I_num=1, Z, W)\n",
    "    δ = []\n",
    "    for mkt in 1:length(X_all)\n",
    "        δ_mkt = invert_s(s=s_all[mkt], X=X_all[mkt], I_n=I_num, σ=σ, ζ=ζ, J=length(s_all[mkt]))\n",
    "        push!(δ, δ_mkt)\n",
    "    end\n",
    "    δ_σ_stack = reduce(vcat, δ)\n",
    "    X_stack = reduce(vcat, X_all)\n",
    "\n",
    "    αβ = θ_tsls(X=X_stack, Z=Z, W=W, δ=δ_σ_stack)\n",
    "\n",
    "    ξ = δ_σ_stack .- (X_stack * αβ)\n",
    "    return (ξ = ξ, δ_all = δ, αβ = αβ)\n",
    "end\n",
    "\n",
    "\n",
    "# Rewrite objective function as only a function of σ\n",
    "function f_gmm_rclogit_σ(;W, Z, X_all, σ, s_all, ζ, I_num)\n",
    "    output = ξδθ_σ_rclogit(X_all=X_all, σ=σ, s_all=s_all, ζ=ζ, I_num=I_num, Z=Z, W=W)\n",
    "    ξ = output.ξ\n",
    "    return (Z' * ξ)' * W * (Z' * ξ)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.074969033894894"
      ]
     },
     "execution_count": 736,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test objective function at σ=0\n",
    "f_gmm_rclogit_σ(W=W_test, Z=Z_test, X_all=test_data[1], σ=zeros(6)', s_all=test_data[2], ζ=ζ_test, \n",
    "    I_num=I_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.134218946935181"
      ]
     },
     "execution_count": 783,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test objective function at σ=0 (only market 17)\n",
    "f_gmm_rclogit_σ(W=inv(Z_17' * Z_17), Z=Z_17, X_all=[test_data[1][17]], σ=zeros(6)', s_all=[test_data[2][17]], \n",
    "    ζ=ζ_test, I_num=I_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9×9 Array{Float64,2}:\n",
       "  0.0284132    -0.00237115   -0.0126792    …   0.00152733   -0.000417313\n",
       " -0.00237115    0.000479658   0.00100226      -0.00109375   -0.00100517\n",
       " -0.0126792     0.00100226    0.00809334      -0.000931723   0.000182673\n",
       " -0.00771592    0.00014338    0.00276867      -0.000362551   0.000154876\n",
       " -0.00332249   -0.000369468   0.000845524     -0.000244754   0.00055841\n",
       "  0.00149303   -0.0011736    -0.000803375  …   0.000968919   0.000398021\n",
       "  0.000499247  -0.000975531  -0.000572778     -0.00025748   -0.00036107\n",
       "  0.00152733   -0.00109375   -0.000931723      0.0203565    -0.000652484\n",
       " -0.000417313  -0.00100517    0.000182673     -0.000652484   0.0203369"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with expanded instrument set\n",
    "X_no_inst = reduce(vcat, test_data[1])[:,2:6]\n",
    "Z_full = hcat(X_no_inst, Z_test)\n",
    "W_full = inv(Z_full' * Z_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7241370155056186"
      ]
     },
     "execution_count": 745,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_gmm_rclogit_σ(W=W_full, Z=Z_full, X_all=test_data[1], σ=zeros(6)', s_all=test_data[2], ζ=ζ_test, I_num=I_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 12\n",
    "\n",
    "##### Write gradient function (as a function of $\\sigma$ only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ξ_Jac (generic function with 1 method)"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Individual share predictor function (given X and αβ)\n",
    "function sHat_ind_αβ(; αβ, X, σ, ζ=0.0, I_n=1)\n",
    "    # Construct numerators\n",
    "    δ = X * αβ\n",
    "    const_term = repeat(δ', outer=I_n)\n",
    "    rc_term = ζ * (X .* repeat(σ, outer=length(δ)))'\n",
    "    exp_term = const_term .+ rc_term\n",
    "    max_exp = maximum(exp_term, dims=2)\n",
    "    num = exp.(exp_term - repeat(max_exp, inner=(1,length(δ))))\n",
    "\n",
    "    # Construct denominators and shares\n",
    "    denom = repeat(exp.(-max_exp) .+ sum(num, dims=2), inner=(1,length(δ)))\n",
    "    ŝ_i = num ./ denom\n",
    "    return ŝ_i\n",
    "end\n",
    "\n",
    "\n",
    "# Function to compute Jacobian of ξ(θ) for each market\n",
    "function ξ_Jac_θ_mkt(; X, I_n, ζ, ŝ_i)\n",
    "    ξ_J = zeros(size(X)[1], size(X)[1])\n",
    "    J_σ = zeros(size(X)[1], size(X)[2])\n",
    "    for i in 1:I_n\n",
    "        s = ŝ_i[i,:]\n",
    "        ξ_Ji = -1.0 * ((s * s') .- diagm(vec(s)))\n",
    "        ξ_J = ξ_J .+ (1/I_n) .* ξ_Ji\n",
    "        J_σ = J_σ .+ (ξ_Ji * X) * diagm(ζ[i,:])\n",
    "    end\n",
    "    return -1.0 * inv(ξ_J) * J_σ./I_n\n",
    "end\n",
    "\n",
    "\n",
    "# Function for computing Jacobian of ξ(θ) for all markets\n",
    "function ξ_Jac(; X_all, αβ, I_n, ζ, σ)\n",
    "      ξ_J_θ = []\n",
    "      for mkt in 1:length(X_all)\n",
    "            X_mkt = X_all[mkt];\n",
    "            ŝ_i = sHat_ind_αβ(αβ=αβ, X=X_mkt, σ=σ, ζ=ζ, I_n=I_n)\n",
    "            ξ_J_θ_mkt = ξ_Jac_θ_mkt(X=X_mkt, I_n=I_n, ζ=ζ, ŝ_i=ŝ_i)\n",
    "            push!(ξ_J_θ, ξ_J_θ_mkt)\n",
    "      end\n",
    "      ξ_J = reduce(vcat, ξ_J_θ)\n",
    "      return ξ_J\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test function for Jacobian (first compute $\\delta$ values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "ξδθ_output =  ξδθ_σ_rclogit(X_all=test_data[1], σ=zeros(6)', s_all=test_data[2], ζ=ζ_test, I_num=25, \n",
    "        Z=Z_test, W=W_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "ξ_Jac_test = ξ_Jac(X_all=test_data[1], αβ=ξδθ_output.αβ, I_n=I_test, ζ=ζ_test, σ=zeros(6)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f_gmm_rclogit_σ_g (generic function with 1 method)"
      ]
     },
     "execution_count": 770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function f_gmm_rclogit_σ_g(; X_all, αβ, Z, W, σ, I_n, ζ, ξ)\n",
    "      ξ_J = ξ_Jac(X_all=X_all, αβ=αβ, I_n=I_n, ζ=ζ, σ=σ)\n",
    "      df_θ = 2 * (Z' * ξ_J)' * W * (Z' * ξ)\n",
    "      return df_θ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " 167.999  -3.9062  -361.426  -17.5974  -1.74867  -4.98657"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_test_gmm_g = f_gmm_rclogit_σ_g(X_all=test_data[1], αβ=ξδθ_output.αβ, Z=Z_test, W=W_test, \n",
    "    σ=zeros(6)', I_n=I_test, ζ=ζ_test, ξ=ξδθ_output.ξ)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " 108.898  6.98789  -855.482  -10.4397  -3.75373  -3.2973"
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_test_gmm_g = f_gmm_rclogit_σ_g(X_all=test_data[1], αβ=ξδθ_output.αβ, Z=Z_test, W=W_test, \n",
    "    σ=0.1*ones(6)', I_n=I_test, ζ=ζ_test, ξ=ξδθ_output.ξ)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "ξδθ_output_full =  ξδθ_σ_rclogit(X_all=test_data[1], σ=zeros(6)', s_all=test_data[2], ζ=ζ_test, I_num=25, \n",
    "        Z=Z_full, W=W_full);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " -3.39817e-12  -6.63114e-13  -1.36525e-11  …  -8.40764e-14  -5.29683e-13"
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_test_gmm_g_full = f_gmm_rclogit_σ_g(X_all=test_data[1], αβ=ξδθ_output_full.αβ, Z=Z_full, W=W_full, \n",
    "    σ=zeros(6)', I_n=I_test, ζ=ζ_test, ξ=ξδθ_output_full.ξ)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " 0.176603  0.0154844  -0.517688  0.0372508  0.014842  -0.0960557"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_test_gmm_g_full = f_gmm_rclogit_σ_g(X_all=test_data[1], αβ=ξδθ_output_full.αβ, Z=Z_full, W=W_full, \n",
    "    σ=0.1*ones(6)', I_n=I_test, ζ=ζ_test, ξ=ξδθ_output_full.ξ)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Jacobian of market shares using ForwardDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmm_σ_test_17_hybrid (generic function with 1 method)"
      ]
     },
     "execution_count": 788,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gmm_σ_test(σ_init) \n",
    "    func = f_gmm_rclogit_σ(W=W_test, Z=Z_test, X_all=test_data[1], σ=σ_init,\n",
    "                        s_all=test_data[2], ζ=ζ_test, I_num=I_test)\n",
    "    return func\n",
    "end\n",
    "function gmm_σ_test_full(σ_init) \n",
    "    func = f_gmm_rclogit_σ(W=W_full, Z=Z_full, X_all=test_data[1], σ=σ_init,\n",
    "                        s_all=test_data[2], ζ=ζ_test, I_num=I_test)\n",
    "    return func\n",
    "end\n",
    "function gmm_σ_test_17(σ_init) \n",
    "    func = f_gmm_rclogit_σ(W=inv(Z_17' * Z_17), Z=Z_17, X_all=[test_data[1][17]], σ=σ_init,\n",
    "                        s_all=[test_data[2][17]], ζ=ζ_test, I_num=I_test)\n",
    "    return func\n",
    "end\n",
    "function gmm_σ_test_17_hybrid(σ_init) \n",
    "    func = f_gmm_rclogit_σ(W=W_test, Z=Z_17, X_all=[test_data[1][17]], σ=σ_init,\n",
    "                        s_all=[test_data[2][17]], ζ=ζ_test, I_num=I_test)\n",
    "    return func\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing market 17 data (Wtest is Z' Z in the full data, while Ztest is Z (that is, z1-z4) in the full datset.  The \"full\" function above uses the non-price components of X in addition to z1-z4, while the one without it just uses z1-z4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " -0.477877  -0.0901108  19.6532  1.60996  -0.120795  -0.155871"
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ForwardDiff.gradient(gmm_σ_test_17, zeros(6)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " 0.775587  -0.00532314  1.05911  -0.00579238  0.000214525  0.0234819"
      ]
     },
     "execution_count": 789,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ForwardDiff.gradient(gmm_σ_test_17_hybrid, zeros(6)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " -18.5407  0.848794  -58.1831  -3.29526  0.213449  0.727438"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_test_gmm_J = ForwardDiff.gradient(gmm_σ_test, zeros(6)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " -0.600852  0.11516  17.4269  -0.600072  0.0257749  0.00282269"
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_test_gmm_J = ForwardDiff.gradient(gmm_σ_test, 0.1*ones(6)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " 9.80254e-15  1.80136e-15  -3.98197e-14  …  4.40205e-16  7.56832e-15"
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_test_gmm_J_full = ForwardDiff.gradient(gmm_σ_test_full, zeros(6)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " 0.159545  0.0124774  0.9445  0.0402245  0.0411288  -0.110281"
      ]
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_test_gmm_J_full = ForwardDiff.gradient(gmm_σ_test_full, 0.1*ones(6)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This part below is what appears to be working ok (I think the negativity components shouldn't matter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f_gmm_rclogit_σ_g (generic function with 1 method)"
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function f_gmm_rclogit_σ_g(; X_all, s_all, Z, W, σ, I_n, ζ)\n",
    "    ξδθ_output =  ξδθ_σ_rclogit(X_all=X_all, σ=σ, s_all=s_all, ζ=ζ, I_num=I_n, Z=Z, W=W);\n",
    "    ξ_J = ξ_Jac(X_all=X_all, αβ=ξδθ_output.αβ, I_n=I_n, ζ=ζ, σ=σ)\n",
    "    df_θ = 2 * (Z' * ξ_J)' * W * (Z' * ξδθ_output.ξ)\n",
    "    return df_θ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " 167.999  -3.9062  -361.426  -17.5974  -1.74867  -4.98657"
      ]
     },
     "execution_count": 781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_gmm_rclogit_σ_g(X_all=test_data[1], s_all=test_data[2], Z=Z_test, W=W_test, σ=zeros(6)', I_n=25, \n",
    "    ζ=ζ_test)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " 122.409  7.61255  -940.025  -11.6758  -4.52968  -3.75602"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_gmm_rclogit_σ_g(X_all=test_data[1], s_all=test_data[2], Z=Z_test, W=W_test, σ=0.1*ones(6)', I_n=25, \n",
    "    ζ=ζ_test)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " 0.206239  0.0177008  -0.456702  0.0315402  0.017417  -0.107985"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_gmm_rclogit_σ_g(X_all=test_data[1], s_all=test_data[2], Z=Z_full, W=W_full, σ=0.1*ones(6)', I_n=25, \n",
    "    ζ=ζ_test)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " -4.09185  0.104914  11.5972  0.31544  -0.0609314  0.239433"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_gmm_rclogit_σ_g(X_all=[test_data[1][17]], s_all=[test_data[2][17]], Z=Z_17, W=inv(Z_17' * Z_17), \n",
    "    σ=zeros(6)', I_n=25, ζ=ζ_test)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " 0.136764  -0.00405394  -0.369051  -0.0170434  -7.8023e-5  -0.00651925"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_gmm_rclogit_σ_g(X_all=[test_data[1][17]], s_all=[test_data[2][17]], Z=Z_17, W=W_test, \n",
    "    σ=zeros(6)', I_n=25, ζ=ζ_test)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n",
    "\n",
    "## Question 13\n",
    "\n",
    "##### Write GMM function that only takes in the desired values of $\\sigma$ (for random coefficients on price and engine size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmm_σ (generic function with 1 method)"
      ]
     },
     "execution_count": 761,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gmm_σ(σ_init) \n",
    "    σ_mod = [σ_init[1], 0, σ_init[2], 0, 0, 0]' # Only price and engine size have RCs\n",
    "    func = f_gmm_rclogit_σ(W=W_test, Z=Z_test, X_all=test_data[1], σ=σ_mod,\n",
    "                        s_all=test_data[2], ζ=ζ_test, I_num=I_test)\n",
    "    return func\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.074969033894894"
      ]
     },
     "execution_count": 762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test GMM function\n",
    "gmm_σ(zeros(2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmm_σ_full (generic function with 1 method)"
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gmm_σ_full(σ_init) \n",
    "    σ_mod = [σ_init[1], 0, σ_init[2], 0, 0, 0]' # Only price and engine size have RCs\n",
    "    func = f_gmm_rclogit_σ(W=W_full, Z=Z_full, X_all=test_data[1], σ=σ_mod,\n",
    "                        s_all=test_data[2], ζ=ζ_test, I_num=I_test)\n",
    "    return func\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7241370155056186"
      ]
     },
     "execution_count": 764,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test GMM function\n",
    "gmm_σ_full(zeros(2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEMPORARILY - construct auto-diff function as placeholder for coded-up one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×2 Adjoint{Float64,Array{Float64,1}}:\n",
       " 822.838  3291.01"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct auto-diff function as placeholder\n",
    "g_gmm_σ_auto = x -> ForwardDiff.gradient(gmm_σ, x)\n",
    "g_gmm_σ_auto(ones(2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×2 Adjoint{Float64,Array{Float64,1}}:\n",
       " -0.114101  51.1676"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct auto-diff function as placeholder\n",
    "g_gmm_σ_auto_full = x -> ForwardDiff.gradient(gmm_σ_full, x)\n",
    "g_gmm_σ_auto_full(ones(2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×2 Adjoint{Float64,Array{Float64,1}}:\n",
       " 0.130684  1.14489"
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_gmm_σ_auto_full(0.1 * ones(2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write function for calling one stage of GMM for a given weighting matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmm_stage (generic function with 1 method)"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gmm_stage(; W, Z, X_all, s_all, ζ, I_num, σ_init)\n",
    "    # Objective function\n",
    "    function f_obj(σ_init) \n",
    "        σ_mod = [σ_init[1], 0, σ_init[2], 0, 0, 0]' # Only price and engine size have RCs\n",
    "        func = f_gmm_rclogit_σ(W=W, Z=Z, X_all=X_all, σ=σ_mod, s_all=s_all, ζ=ζ, I_num=I_num)\n",
    "        return func\n",
    "    end\n",
    "    \n",
    "    # Gradient function\n",
    "#     function g_obj(σ_init)\n",
    "#         σ_mod = [σ_init[1], 0, σ_init[2], 0, 0, 0]' # Only price and engine size have RCs\n",
    "#         grad = f_gmm_rclogit_σ_g(W=W, Z=Z, X_all=X_all, σ=σ_mod, s_all=s_all, ζ=ζ, I_num=I_num) \n",
    "#         G[1:2] = grad[1,3]\n",
    "#     end\n",
    "    \n",
    "    # AD gradient function\n",
    "    g_gmm_σ_auto_test = x -> ForwardDiff.gradient(f_obj, x)\n",
    "    function g_obj(G, σ_init)\n",
    "        grad = g_gmm_σ_auto_test(σ_init)\n",
    "        G[1:2] = grad[1:2]\n",
    "    end\n",
    "    \n",
    "    # Return result\n",
    "    σ_result = Optim.minimizer(optimize(f_obj, g_obj, σ_init, BFGS(), Optim.Options(show_trace=true)))\n",
    "    return σ_result\n",
    "end  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter     Function value   Gradient norm \n",
      "     0     7.801446e-01     1.144892e+00\n",
      " * time: 0.0007359981536865234\n",
      "     1     7.664995e-01     9.297282e-01\n",
      " * time: 51.830342054367065\n",
      "     2     7.288072e-01     2.575596e-01\n",
      " * time: 156.80731296539307\n",
      "     3     7.243450e-01     3.826922e-02\n",
      " * time: 196.7523410320282\n",
      "     4     7.241371e-01     7.535814e-04\n",
      " * time: 257.3205749988556\n",
      "     5     7.241370e-01     5.741963e-06\n",
      " * time: 362.20552682876587\n",
      "     6     7.241370e-01     1.438635e-11\n",
      " * time: 434.5701470375061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       "  2.912537762558837e-12\n",
       " -1.7766381381950007e-12"
      ]
     },
     "execution_count": 769,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_stage(W=W_full, Z=Z_full, X_all=test_data[1], s_all=test_data[2], ζ=ζ_test, I_num=I_test, \n",
    "    σ_init=0.1*ones(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_stage(W=W_full, Z=Z_full, X_all=test_data[1], s_all=test_data[2], ζ=ζ_test, I_num=I_test, \n",
    "    σ_init=0.1*ones(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write functions for implementing two-stage GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for optimal weighting matrix\n",
    "function gmm_opt_weight(; Z, ξ)\n",
    "    n = size(Z)[1]\n",
    "    Zξ = Z' * ξ\n",
    "    return inv((1/n) * Zξ * Zξ')\n",
    "end\n",
    "\n",
    "\n",
    "# Function for gradient of ξ with respect to all parameters - STILL NEED TO FINISH THIS!!!!!!!!!!!!!!!!!!!!!!!\n",
    "function ξ_θfull_J(; Z, ξ)\n",
    "    n = size(Z)[1]\n",
    "    Zξ = Z' * ξ\n",
    "    return inv((1/n) * Zξ * Zξ')\n",
    "end\n",
    "\n",
    "\n",
    "# Function for two-stage GMM\n",
    "function two_stage_gmm(; W_stage1, Z, X_all, s_all, ζ, I_num, σ_init)\n",
    "    # First stage estimation with given starting weighting matrix\n",
    "    σ_stage1 = gmm_stage(W=W_stage1, Z=Z, X_all=X_all, s_all=s_all, ζ=ζ, I_num=I_num, σ_init=σ_init)\n",
    "    \n",
    "    # Compute optimal weighting matrix for second stage\n",
    "    ξδθ_output =  ξδθ_σ_rclogit(X_all=X_all, σ=σ_stage1, s_all=s_all, ζ=ζ, I_num=I_num, Z=Z, W=W_stage1)\n",
    "    ξ_stage1 = ξδθ_output.ξ\n",
    "    W_stage2 = gmm_opt_weight(Z=Z, ξ=ξ_stage1)\n",
    "    \n",
    "    # Second stage estimation with given starting weighting matrix\n",
    "    σ_stage2 = gmm_stage(W=W_stage2, Z=Z, X_all=X_all, s_all=s_all, ζ=ζ, I_num=I_num, σ_init=σ_stage1)\n",
    "    \n",
    "    # Compute covariance matrix for point estimates\n",
    "    G = ξ_θfull_J(Z, ξ) # STILL NEED TO FINISH THIS HERE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    ξδθ_output =  ξδθ_σ_rclogit(X_all=X_all, σ=σ_stage1, s_all=s_all, ζ=ζ, I_num=I_num, Z=Z, W=W_stage1)\n",
    "    ξ_stage1 = ξδθ_output.ξ\n",
    "    W_stage2 = gmm_opt_weight(Z=Z, ξ=ξ_stage1)\n",
    "    Σ = inv(G' * inv(W_stage2) * G)\n",
    "    \n",
    "    # Return values\n",
    "    return (σ = σ_stage2, αβ = ξδθ_output.αβ, Σ = Σ)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 14\n",
    "\n",
    "##### Use PyBLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <module 'os' from '/Users/JoshuaHigbee/.julia/conda/3/lib/python3.8/os.py'>"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyblp = pyimport(\"pyblp\")\n",
    "np = pyimport(\"numpy\")\n",
    "pd = pyimport(\"pandas\")\n",
    "os = pyimport(\"os\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/JoshuaHigbee/Box/2. Second Year/2. Winter Quarter - 2021/Industrial Organization II - Hortacsu/Problem Sets/Problem Set 1\""
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Market</th>\n",
       "      <th>Constant</th>\n",
       "      <th>Price</th>\n",
       "      <th>EngineSize</th>\n",
       "      <th>SportsBike</th>\n",
       "      <th>Brand2</th>\n",
       "      <th>Brand3</th>\n",
       "      <th>z1</th>\n",
       "      <th>z2</th>\n",
       "      <th>z3</th>\n",
       "      <th>z4</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.554708</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.237685</td>\n",
       "      <td>0.063116</td>\n",
       "      <td>0.034361</td>\n",
       "      <td>0.056459</td>\n",
       "      <td>0.239077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.559811</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.186073</td>\n",
       "      <td>0.326445</td>\n",
       "      <td>0.062091</td>\n",
       "      <td>0.072184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.857186</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164550</td>\n",
       "      <td>0.033308</td>\n",
       "      <td>0.075316</td>\n",
       "      <td>0.278736</td>\n",
       "      <td>0.000460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.995438</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.485538</td>\n",
       "      <td>0.117025</td>\n",
       "      <td>0.345850</td>\n",
       "      <td>0.084891</td>\n",
       "      <td>0.587867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.017987</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582503</td>\n",
       "      <td>0.368032</td>\n",
       "      <td>0.652134</td>\n",
       "      <td>0.509693</td>\n",
       "      <td>0.033746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>2.010710</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.257544</td>\n",
       "      <td>0.068546</td>\n",
       "      <td>0.095527</td>\n",
       "      <td>0.185333</td>\n",
       "      <td>0.000548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>2.001591</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042531</td>\n",
       "      <td>0.474048</td>\n",
       "      <td>0.285886</td>\n",
       "      <td>0.263406</td>\n",
       "      <td>0.024166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1.692977</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021038</td>\n",
       "      <td>0.453095</td>\n",
       "      <td>0.079379</td>\n",
       "      <td>0.276368</td>\n",
       "      <td>0.355868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>2.337965</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.565742</td>\n",
       "      <td>0.190674</td>\n",
       "      <td>0.695795</td>\n",
       "      <td>0.044509</td>\n",
       "      <td>0.347937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>4.683845</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.474889</td>\n",
       "      <td>0.348956</td>\n",
       "      <td>0.225896</td>\n",
       "      <td>0.692309</td>\n",
       "      <td>0.008260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1047 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "PyObject       Market  Constant     Price  ...        z3        z4    shares\n",
       "0          1         1  1.554708  ...  0.034361  0.056459  0.239077\n",
       "1          1         1  1.559811  ...  0.326445  0.062091  0.072184\n",
       "2          1         1  1.857186  ...  0.075316  0.278736  0.000460\n",
       "3          1         1  1.995438  ...  0.345850  0.084891  0.587867\n",
       "4          1         1  4.017987  ...  0.652134  0.509693  0.033746\n",
       "...      ...       ...       ...  ...       ...       ...       ...\n",
       "1042     150         1  2.010710  ...  0.095527  0.185333  0.000548\n",
       "1043     150         1  2.001591  ...  0.285886  0.263406  0.024166\n",
       "1044     150         1  1.692977  ...  0.079379  0.276368  0.355868\n",
       "1045     150         1  2.337965  ...  0.695795  0.044509  0.347937\n",
       "1046     150         1  4.683845  ...  0.225896  0.692309  0.008260\n",
       "\n",
       "[1047 rows x 12 columns]"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_data = pd.read_csv(\"psetOne.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data.rename(columns=Dict(\"Price\"=>\"prices\", \"Market\"=>\"market_ids\", \"z1\"=>\"demand_instruments0\",\n",
    "        \"z2\"=>\"demand_instruments1\", \"z3\"=>\"demand_instruments2\", \"z4\"=>\"demand_instruments3\"), inplace=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PyObject 1 + prices + EngineSize + SportsBike + Brand2 + Brand3, PyObject prices + EngineSize)"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_formulations = (pyblp.Formulation(\"prices + 1 + EngineSize + SportsBike + Brand2 + Brand3\"),\n",
    "   pyblp.Formulation(\"0 + prices + EngineSize\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject Configured to construct nodes and weights with Monte Carlo simulation with options {seed: 12345}."
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_integration = pyblp.Integration(\"monte_carlo\", size=25, specification_options=Dict(\"seed\"=>12345))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject Dimensions:\n",
       "=================================\n",
       " T    N     I     K1    K2    MD \n",
       "---  ----  ----  ----  ----  ----\n",
       "150  1047  3750   6     2     9  \n",
       "=================================\n",
       "\n",
       "Formulations:\n",
       "=========================================================================================\n",
       "       Column Indices:           0         1           2           3         4       5   \n",
       "-----------------------------  ------  ----------  ----------  ----------  ------  ------\n",
       " X1: Linear Characteristics      1       prices    EngineSize  SportsBike  Brand2  Brand3\n",
       "X2: Nonlinear Characteristics  prices  EngineSize                                        \n",
       "========================================================================================="
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem = pyblp.Problem(product_formulations, product_data, integration=mc_integration, add_exogenous=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject Configured to optimize using the BFGS algorithm implemented in SciPy with analytic gradients and options {gtol: +1.000000E-04}."
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfgs = pyblp.Optimization(\"bfgs\", Dict(\"gtol\"=>1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIALIZE STARTING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the problem ...\n",
      "Initializing the problem ...\n",
      "Initializing the problem ...\n",
      "Initializing the problem ...\n",
      "Initializing the problem ...\n",
      "Initializing the problem ...\n",
      "Initializing the problem ...\n",
      "Initializing the problem ...\n",
      "Initializing the problem ...\n",
      "Initializing the problem ...\n",
      "Initialized the problem after 00:00:00.\n",
      "\n",
      "Dimensions:\n",
      "=================================\n",
      " T    N     I     K1    K2    MD \n",
      "---  ----  ----  ----  ----  ----\n",
      "150  1047  3750   6     3     9  \n",
      "=================================\n",
      "\n",
      "Formulations:\n",
      "==================================================================================\n",
      "       Column Indices:          0     1         2           3         4       5   \n",
      "-----------------------------  ---  ------  ----------  ----------  ------  ------\n",
      " X1: Linear Characteristics     1   prices  EngineSize  SportsBike  Brand2  Brand3\n",
      "X2: Nonlinear Characteristics   1   prices  EngineSize                            \n",
      "==================================================================================\n",
      "Initializing the problem ...\n",
      "Initialized the problem after 00:00:00.\n",
      "\n",
      "Dimensions:\n",
      "=================================\n",
      " T    N     I     K1    K2    MD \n",
      "---  ----  ----  ----  ----  ----\n",
      "150  1047  3750   6     2     9  \n",
      "=================================\n",
      "\n",
      "Formulations:\n",
      "=========================================================================================\n",
      "       Column Indices:           0         1           2           3         4       5   \n",
      "-----------------------------  ------  ----------  ----------  ----------  ------  ------\n",
      " X1: Linear Characteristics      1       prices    EngineSize  SportsBike  Brand2  Brand3\n",
      "X2: Nonlinear Characteristics  prices  EngineSize                                        \n",
      "=========================================================================================\n",
      "Solving the problem ...\n",
      "Solving the problem ...\n",
      "Solving the problem ...\n",
      "\n",
      "Nonlinear Coefficient Initial Values:\n",
      "========================================\n",
      "  Sigma:       prices       EngineSize  \n",
      "----------  -------------  -------------\n",
      "  prices    +1.000000E+00               \n",
      "EngineSize  +0.000000E+00  +1.000000E+00\n",
      "========================================\n",
      "\n",
      "Nonlinear Coefficient Lower Bounds:\n",
      "========================================\n",
      "  Sigma:       prices       EngineSize  \n",
      "----------  -------------  -------------\n",
      "  prices        -INF                    \n",
      "EngineSize  +0.000000E+00      -INF     \n",
      "========================================\n",
      "\n",
      "Nonlinear Coefficient Upper Bounds:\n",
      "========================================\n",
      "  Sigma:       prices       EngineSize  \n",
      "----------  -------------  -------------\n",
      "  prices        +INF                    \n",
      "EngineSize  +0.000000E+00      +INF     \n",
      "========================================\n",
      "\n",
      "Starting optimization ...\n",
      "\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "The fixed point computation of delta failed to converge. This problem can sometimes be mitigated by increasing the maximum number of fixed point iterations, increasing the fixed point tolerance, choosing more reasonable initial parameter values, setting more conservative parameter or share bounds, or using different iteration or optimization configurations.\n",
      "\n",
      "GMM   Optimization   Objective   Fixed Point  Contraction  Clipped    Objective      Objective      Gradient                                 \n",
      "Step   Iterations   Evaluations  Iterations   Evaluations  Shares       Value       Improvement       Norm                  Theta            \n",
      "----  ------------  -----------  -----------  -----------  -------  -------------  -------------  -------------  ----------------------------\n",
      " 1         0             1          15214        45843        0     +2.387291E+03                 +1.461937E+04  +1.000000E+00, +1.000000E+00\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         0             2          4753         14387        0     +2.197641E+03  +1.896504E+02  +4.420914E+03  +1.024164E+00, -9.710910E-03\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         1             3          4101         12461        0     +1.375243E+03  +8.223979E+02  +3.290879E+03  +9.342912E-01, -3.806529E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         2             4          3089         9428         0     +1.914607E+03                 +3.191999E+03  +6.332263E-01, +6.470769E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         2             5          3860         11723        0     +4.366448E+02  +9.385980E+02  +1.978065E+03  +8.913314E-01, -2.340031E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         3             6          4306         13082        0     +4.253682E+02  +1.127656E+01  +1.715530E+03  +8.177064E-01, -2.883877E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4             7          3694         11238        0     +3.558622E+02  +6.950601E+01  +1.687228E+03  +8.043448E-01, -2.911285E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4             8          4777         14493        0     +9.544917E+02                 +2.554006E+03  +7.508982E-01, -3.020919E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4             9          3719         11306        0     +3.074968E+03                 +4.767947E+03  +8.031858E-01, -2.913662E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            10          4300         13055        0     +7.443207E+02                 +2.282908E+03  +8.043446E-01, -2.911285E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            11          3375         10286        0     +6.621006E+02                 +2.247042E+03  +8.043448E-01, -2.911285E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            12          3694         11238        0     +2.701283E+03                 +4.495991E+03  +8.043448E-01, -2.911285E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            13          3738         11368        0     +1.400398E+03                 +3.169867E+03  +8.110256E-01, -2.897581E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            14          4223         12832        0     +8.114722E+02                 +2.379882E+03  +8.143660E-01, -2.890729E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            15          4684         14197        4     +1.142874E+40                 +4.089230E+21  +8.160362E-01, -2.887303E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            16          4621         14032        0     +9.609128E+02                 +2.633310E+03  +8.168713E-01, -2.885590E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            17          4756         14412        0     +1.817748E+03                 +3.739403E+03  +8.171497E-01, -2.885019E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            18          4168         12669        0     +1.843546E+03                 +3.654653E+03  +8.174280E-01, -2.884448E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            19          3594         10944        0     +9.977433E+02                 +2.639530E+03  +8.175672E-01, -2.884162E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            20          3842         11689        0     +2.305232E+03                 +3.882946E+03  +8.176368E-01, -2.884019E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            21          3726         11335        0     +1.121075E+03                 +2.922032E+03  +8.176716E-01, -2.883948E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            22          3895         11845        0     +3.122427E+02  +4.361952E+01  +1.596819E+03  +8.176890E-01, -2.883912E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            23          3727         11349        0     +1.344756E+03                 +3.088230E+03  +8.176803E-01, -2.883930E-02\n",
      "\n",
      "The optimization routine failed to converge. This problem can sometimes be mitigated by choosing more reasonable initial parameter values, setting more conservative bounds, or configuring other optimization settings.\n",
      "\n",
      "\n",
      "Optimization failed after 00:00:55.\n",
      "Computing the Hessian and and updating the weighting matrix ...\n",
      "\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      "Computed results after 00:00:11.\n",
      "\n",
      "Problem Results Summary:\n",
      "=============================================================================================\n",
      "GMM     Objective      Gradient         Hessian         Hessian     Clipped  Weighting Matrix\n",
      "Step      Value          Norm       Min Eigenvalue  Max Eigenvalue  Shares   Condition Number\n",
      "----  -------------  -------------  --------------  --------------  -------  ----------------\n",
      " 1    +2.023679E+03  +3.808412E+03  -5.468419E+10   +9.135132E+09      0      +2.296230E+03  \n",
      "=============================================================================================\n",
      "\n",
      "Starting optimization ...\n",
      "\n",
      "GMM   Optimization   Objective   Fixed Point  Contraction  Clipped    Objective      Objective      Gradient                                 \n",
      "Step   Iterations   Evaluations  Iterations   Evaluations  Shares       Value       Improvement       Norm                  Theta            \n",
      "----  ------------  -----------  -----------  -----------  -------  -------------  -------------  -------------  ----------------------------\n",
      " 2         0             1            9           182         0     +4.225440E+01                 +2.369560E+02  +8.177064E-01, -2.883877E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "The fixed point computation of delta failed to converge. This problem can sometimes be mitigated by increasing the maximum number of fixed point iterations, increasing the fixed point tolerance, choosing more reasonable initial parameter values, setting more conservative parameter or share bounds, or using different iteration or optimization configurations.\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 2         0             2          6763         20441        0     +7.782877E+04                 +4.176063E+03  -1.073192E-01, +3.766580E-01\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 2         0             3          3016         9210         0     +7.219808E+01                 +3.152732E+02  +8.171946E-01, -2.861442E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 2         0             4          2274         6944         0     +2.239749E+01  +1.985691E+01  +1.599900E+02  +8.177060E-01, -2.883859E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "The fixed point computation of delta failed to converge. This problem can sometimes be mitigated by increasing the maximum number of fixed point iterations, increasing the fixed point tolerance, choosing more reasonable initial parameter values, setting more conservative parameter or share bounds, or using different iteration or optimization configurations.\n",
      "\n",
      " 2         1             5          35374       106315        0     +2.854991E+03                 +6.601037E+03  +2.501274E+00, +3.994846E+00\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "The fixed point computation of delta failed to converge. This problem can sometimes be mitigated by increasing the maximum number of fixed point iterations, increasing the fixed point tolerance, choosing more reasonable initial parameter values, setting more conservative parameter or share bounds, or using different iteration or optimization configurations.\n",
      "\n",
      " 2         1             6          16025        48272        0     +1.634675E+03                 +6.695495E+03  +1.306066E+00, +1.138329E+00\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 2         1             7          4837         14670        0     +1.573618E+02                 +1.100428E+03  +9.274308E-01, +2.334009E-01\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 2         1             8          3477         10570        0     +8.698811E+01                 +3.479434E+02  +8.184246E-01, -2.712102E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 2         1             9          3588         10904        0     +5.765584E+01                 +2.668248E+02  +8.177060E-01, -2.883855E-02"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject Problem Results Summary:\n",
       "================================================================================================================\n",
       "GMM     Objective      Gradient         Hessian         Hessian     Clipped  Weighting Matrix  Covariance Matrix\n",
       "Step      Value          Norm       Min Eigenvalue  Max Eigenvalue  Shares   Condition Number  Condition Number \n",
       "----  -------------  -------------  --------------  --------------  -------  ----------------  -----------------\n",
       " 2    +6.512462E+01  +2.867143E+02  -2.099711E+09   +1.609858E+10      0      +1.565485E+04      +7.208606E+04  \n",
       "================================================================================================================\n",
       "\n",
       "Cumulative Statistics:\n",
       "===========================================================================\n",
       "Computation  Optimizer  Optimization   Objective   Fixed Point  Contraction\n",
       "   Time      Converged   Iterations   Evaluations  Iterations   Evaluations\n",
       "-----------  ---------  ------------  -----------  -----------  -----------\n",
       " 00:03:01       No           5            48         300660       909254   \n",
       "===========================================================================\n",
       "\n",
       "Nonlinear Coefficient Estimates (Robust SEs in Parentheses):\n",
       "============================================\n",
       "  Sigma:        prices         EngineSize   \n",
       "----------  ---------------  ---------------\n",
       "  prices     +8.177060E-01                  \n",
       "            (+3.968173E-01)                 \n",
       "                                            \n",
       "EngineSize   +0.000000E+00    -2.883859E-02 \n",
       "                             (+5.138856E-01)\n",
       "============================================\n",
       "\n",
       "Beta Estimates (Robust SEs in Parentheses):\n",
       "====================================================================================================\n",
       "       1             prices         EngineSize       SportsBike         Brand2           Brand3     \n",
       "---------------  ---------------  ---------------  ---------------  ---------------  ---------------\n",
       " +1.851848E+00    -2.604522E+00    +7.085902E-01    +1.201479E+00    -5.454017E-01    +1.040997E+00 \n",
       "(+1.084555E+00)  (+5.048980E-01)  (+8.609543E-02)  (+1.606042E-01)  (+1.325448E-01)  (+2.267028E-01)\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = problem.solve(sigma=np.identity(2), optimization=bfgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 15\n",
    "\n",
    "##### Elasticity matrix for market $t=17$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
