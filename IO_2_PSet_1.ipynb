{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 1\n",
    "\n",
    "#### Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Market\", \"Constant\", \"Price\", \"EngineSize\", \"SportsBike\", \"Brand2\", \"Brand3\", \"z1\", \"z2\", \"z3\", \"z4\", \"shares\"]\n"
     ]
    }
   ],
   "source": [
    "# Set working directory\n",
    "dir = \"/Users/JoshuaHigbee/Box/2. Second Year/2. Winter Quarter - 2021/\" *\n",
    "      \"Industrial Organization II - Hortacsu/Problem Sets/Problem Set 1/\";\n",
    "cd(dir);\n",
    "\n",
    "# Load packages\n",
    "using CSV, DataFrames, Random, Distributions, LinearAlgebra,\n",
    "      LatexPrint, StatsBase, Plots, SpecialFunctions\n",
    "using Optim, ForwardDiff, PyCall\n",
    "\n",
    "# Set seed\n",
    "Random.seed!(12345);\n",
    "\n",
    "# Read in data\n",
    "data = CSV.read(\"psetOne.csv\", DataFrame);\n",
    "println(names(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/><br/>\n",
    "\n",
    "## Question 8\n",
    "\n",
    "#### Load data for market $t=17$, and set up parameter values (coefficient order is Price, Constant, Engine CC, BikeType, Brand2, Brand3) and $\\xi$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data \n",
    "d17 = data[data.Market .== 17, :];\n",
    "\n",
    "# Parameters\n",
    "θ_given =  [-3.0 1.0 1.0 2.0 -1.0 1.0]'\n",
    "α = θ_given[1]\n",
    "\n",
    "# Ownership matrix\n",
    "d17.Brand1 = Ref(1.0) .- max.(d17.Brand2, d17.Brand3);\n",
    "Δ = (d17.Brand1 .* d17.Brand1') .+ (d17.Brand2 .* d17.Brand2') .+ (d17.Brand3 .* d17.Brand3')\n",
    "\n",
    "# ξ values\n",
    "ξ_rand = rand(Normal(0,1),7);\n",
    "ξ_newton = ξ_rand; # ξ_simple\n",
    "ξ_newton = zeros(7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define useful functions for solving fixed point pricing equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newton_fxp (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shares function\n",
    "function s_newton(price)\n",
    "    X = hcat(price, d17.Constant, d17.EngineSize, d17.SportsBike, d17.Brand2, d17.Brand3)\n",
    "    exp_term = X * θ_given .+ ξ_newton\n",
    "    max_exp = maximum(exp_term)\n",
    "    num = exp.(exp_term .- max_exp)\n",
    "    return num / (exp(-max_exp) + sum(num))\n",
    "end\n",
    "\n",
    "\n",
    "# Jacobian of shares function\n",
    "function s_Jac_newton(price)\n",
    "    s = s_newton(price)\n",
    "    return - α * ((s * s') .- diagm(vec(s))) # α is negative in this setting\n",
    "end\n",
    "\n",
    "\n",
    "# Hessian of shares function\n",
    "function s_Hess_newton(price)\n",
    "    s = s_newton(price)\n",
    "    Hess = Array{Float64}(undef, 7, 7, 7)\n",
    "    for j in 1:7\n",
    "        for k in 1:7\n",
    "            for l in 1:7\n",
    "                Hess[j,k,l] = α^2 *\n",
    "                      ((2*s[j]*s[k]*s[l] - 3*s[j]*s[k] + s[j])*(j==k && j==l) +\n",
    "                      (2*s[j]*s[k]*s[l] - s[j]*s[l])*(j==k && j!=l) +\n",
    "                      (2*s[j]*s[k]*s[l] - s[k]*s[l])*(j!=k && j==l) +\n",
    "                      (2*s[j]*s[k]*s[l] - s[j]*s[k])*(j!=k && k==l) +\n",
    "                      (2*s[j]*s[k]*s[l])*(l!=k && k!=j && j!=l))\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return Hess\n",
    "end\n",
    "\n",
    "\n",
    "# Function for Newton's method (using p + Ω^{-1} * s = 0)\n",
    "function f_newton(price)\n",
    "    s = s_newton(price)\n",
    "    s_J = s_Jac_newton(price)\n",
    "    Ω = Δ .* s_J\n",
    "    f = price + inv(Ω) * s\n",
    "    return f\n",
    "end\n",
    "\n",
    "\n",
    "# Jacobian of Ω^{-1} (for use in computing Jacobian of function for fxp est)\n",
    "function Ω_inv_Jac_newton(price)\n",
    "    s = s_newton(price)\n",
    "    s_J = s_Jac_newton(price)\n",
    "    s_H = s_Hess_newton(price)\n",
    "    Ω = Δ .* s_J\n",
    "    Ω_J = Δ .* s_H\n",
    "\n",
    "    Ω_J_inv = Array{Float64}(undef, length(s), length(s), length(s))\n",
    "    for j in 1:length(s)\n",
    "        Ω_J_inv[:,:,j] = - inv(Ω) * Ω_J[:,:,j] * inv(Ω)\n",
    "    end\n",
    "    return Ω_J_inv\n",
    "end\n",
    "\n",
    "\n",
    "# Jacobian of function for Newton's method\n",
    "function f_newton_J(price)\n",
    "    s = s_newton(price)\n",
    "    s_J = s_Jac_newton(price)\n",
    "    Ω = Δ .* s_J\n",
    "    Ω_inv_J = Ω_inv_Jac_newton(price)\n",
    "    Ω_inv_J_times_s = Matrix(0.0 * I, length(s), length(s))\n",
    "    for j in 1:length(s)\n",
    "        Ω_inv_J_times_s[:,j] = Ω_inv_J[:,:,j] * s\n",
    "    end\n",
    "    ∇f_newton = I + Ω_inv_J_times_s + inv(Ω) * s_J\n",
    "    return ∇f_newton\n",
    "end\n",
    "\n",
    "\n",
    "# Actually estimate the fixed point\n",
    "function newton_fxp(price, ϵ)\n",
    "    diff = 1\n",
    "    p_0 = price\n",
    "    iter=1\n",
    "    while diff > ϵ\n",
    "        # Solve equation\n",
    "        fxp = f_newton(p_0)\n",
    "        ∇fxp = f_newton_J(p_0)\n",
    "        # ∇fxp = ForwardDiff.jacobian(f_newton, p_0)\n",
    "        p_1 = p_0 - inv(∇fxp) * fxp\n",
    "\n",
    "        # Update values and loop\n",
    "        diff = maximum(abs.(p_1 .- p_0))\n",
    "        println(\"Iteration \" * string(iter) * \"     Difference \" * string(diff))\n",
    "        p_0 = p_1\n",
    "        iter = iter + 1\n",
    "    end\n",
    "    return p_0\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solve fixed point equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1     Difference 2.484826536163365\n",
      "Iteration 2     Difference 0.2893243176990721\n",
      "Iteration 3     Difference 0.0726965625358531\n",
      "Iteration 4     Difference 0.006524393561025077\n",
      "Iteration 5     Difference 4.2079754713597595e-5\n",
      "Iteration 6     Difference 1.679278494037817e-9\n",
      "Iteration 7     Difference 6.661338147750939e-16\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7×1 Array{Float64,2}:\n",
       " 0.38447413297903904\n",
       " 0.3844741329790391\n",
       " 0.3523194580438232\n",
       " 0.3523194580438232\n",
       " 1.7822602606218438\n",
       " 1.782260260621844\n",
       " 1.782260260621844"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_init = ones(7);\n",
    "p_init = d17.Price;\n",
    "p_optimal = newton_fxp(p_init, 1.0e-10)\n",
    "\n",
    "println(\" \")\n",
    "p_optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check to ensure it is a fixed point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7×1 Array{Float64,2}:\n",
      " -1.1102230246251565e-16\n",
      "  0.0\n",
      "  0.0\n",
      " -5.551115123125783e-17\n",
      "  3.9968028886505635e-15\n",
      "  3.9968028886505635e-15\n",
      "  3.3306690738754696e-15"
     ]
    }
   ],
   "source": [
    "f_newton(p_optimal)\n",
    "show(stdout, \"text/plain\", f_newton(p_optimal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/><br/>\n",
    "\n",
    "## Question 9\n",
    "\n",
    "#### Write share prediction functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sHat_from_ŝ (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Individual share predictor function (given mean utilities)\n",
    "# function sHat_ind(;δ, X=0.0, σ, ζ=0.0, I_n=1)\n",
    "    \n",
    "#     # Fill values if unspecified (default)\n",
    "#     if X == 0.0\n",
    "#         X = repeat(fill(0.0,length(σ))', length(δ))\n",
    "#     end\n",
    "#     if ζ == 0.0\n",
    "#         ζ = reshape(fill(0.0,length(σ)*I_n), I_n, length(σ))\n",
    "#     end\n",
    "\n",
    "#     # Construct numerators\n",
    "#     const_term = repeat(δ', outer=I_n)\n",
    "#     rc_term = ζ * (X .* repeat(σ, outer=length(δ)))'\n",
    "#     exp_term = const_term .+ rc_term\n",
    "#     max_exp = maximum(exp_term, dims=2)\n",
    "#     num = exp.(exp_term - repeat(max_exp, inner=(1,length(δ))))\n",
    "\n",
    "#     # Construct denominators and shares\n",
    "#     denom = repeat(exp.(-max_exp) .+ sum(num, dims=2), inner=(1,length(δ)))\n",
    "#     ŝ_i = num ./ denom\n",
    "#     return ŝ_i\n",
    "# end\n",
    "\n",
    "# Individual share predictor function (given mean utilities)\n",
    "function sHat_ind(;δ, X=0.0, σ, ζ=0.0, I_n=1)\n",
    "    \n",
    "    # Fill values if unspecified (default)\n",
    "    if X == 0.0\n",
    "        X = repeat(fill(0.0,length(σ))', length(δ))\n",
    "    end\n",
    "    if ζ == 0.0\n",
    "        ζ = reshape(fill(0.0,length(σ)*I_n), I_n, length(σ))\n",
    "    end\n",
    "\n",
    "    # Construct numerators\n",
    "    const_term = repeat(δ', outer=I_n)\n",
    "    rc_term = ζ * (X .* repeat(σ, outer=length(δ)))'\n",
    "    exp_term = const_term .+ rc_term\n",
    "    num = exp.(exp_term)\n",
    "\n",
    "    # Construct denominators and shares\n",
    "    denom = repeat(Ref(1.0) .+ sum(num, dims=2), inner=(1,length(δ)))\n",
    "    ŝ_i = num ./ denom\n",
    "    return ŝ_i\n",
    "end\n",
    "\n",
    "# Share predictor function (for heterogeneity)\n",
    "function sHat(;δ, X=0.0, σ, ζ=0.0, I_n=1)\n",
    "    ŝ_i = sHat_ind(δ=δ, X=X, σ=σ, ζ=ζ, I_n=I_n)\n",
    "    ŝ = 1/(I_n) * sum(ŝ_i, dims=1)\n",
    "    return vec(ŝ)\n",
    "end\n",
    "\n",
    "# Share predictor function for taking ŝ after it's already computed\n",
    "function sHat_from_ŝ(; ŝ_i, I_n=1)\n",
    "    ŝ = 1/(I_n) * sum(ŝ_i, dims=1)\n",
    "    return vec(ŝ)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up parameters and data for test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_q9 = [3, 3, 3];\n",
    "δ_q9 = [zeros(J_q9[1]), [40, 20, 20], zeros(J_q9[3])];\n",
    "σ_q9 = [[0.0], [0.0], [0.1]];\n",
    "X_q9 = [[], [], [repeat([1.0], 3), [1.0; 3.0; -1.0], [10.0; 10.0; -3.0]]];\n",
    "I_q9 = [[], [], 50];\n",
    "ζ_q9 = [[], [], reshape(rand(Normal(0,1),length(σ_q9[3])*I_q9[3]), I_q9[3], length(σ_q9[3]))];\n",
    "shares_q9 = [];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test all cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25, 0.25, 0.25]\n"
     ]
    }
   ],
   "source": [
    "# First case\n",
    "s_test = sHat(δ=δ_q9[1], σ=σ_q9[1]);\n",
    "println(s_test);\n",
    "sum(s_test, dims=2)[1]\n",
    "push!(shares_q9, s_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9999999958776928, 2.0611536139418496e-9, 2.0611536139418496e-9]\n"
     ]
    }
   ],
   "source": [
    "# Second case\n",
    "s_test = sHat(δ=δ_q9[2], σ=σ_q9[2]);\n",
    "println(s_test);\n",
    "sum(s_test, dims=2)[1]\n",
    "push!(shares_q9, s_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2499492, 0.2499492, 0.2499492]\n",
      "[0.247299, 0.2547225, 0.2504074]\n",
      "[0.2492555, 0.2492555, 0.2680796]\n"
     ]
    }
   ],
   "source": [
    "# Third case\n",
    "s_test = sHat(δ=δ_q9[3], X=X_q9[3][1], σ=σ_q9[3], ζ=ζ_q9[3], I_n=I_q9[3])\n",
    "println(convert.(Float64,round.(s_test, digits=7)))\n",
    "push!(shares_q9, s_test);\n",
    "\n",
    "s_test = sHat(δ=δ_q9[3], X=X_q9[3][2], σ=σ_q9[3], ζ=ζ_q9[3], I_n=I_q9[3])\n",
    "println(convert.(Float64,round.(s_test, digits=7)))\n",
    "push!(shares_q9, s_test);\n",
    "\n",
    "s_test = sHat(δ=δ_q9[3], X=X_q9[3][3], σ=σ_q9[3], ζ=ζ_q9[3], I_n=I_q9[3])\n",
    "println(convert.(Float64,round.(s_test, digits=7)))\n",
    "push!(shares_q9, s_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/><br/>\n",
    "\n",
    "## Question 10 - - - - - - - CURRENTLY HAS TWO CONTRACTION MAPPING FUNCTIONS\n",
    "\n",
    "#### Create functions for share inversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "invert_s (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Contraction mapping function\n",
    "# function s_contraction_map(;s, X, I_n, σ, ζ, J, L̄=1.0-1.0e-7, output=false)\n",
    "#       δ_0 = convert.(Real, zeros(length(s)))\n",
    "#       L = 0.5 # Initialize contraction mapping ratio\n",
    "#       iter = 0 # Initialize iteration count\n",
    "#       δ_diff = 0.5 # Initialize difference in δ (in case L misbehaves)\n",
    "#       δ_diff_h = Array{Real}(undef, 1, 3)\n",
    "#       while (δ_diff > 1.0e-7) && (L < L̄)\n",
    "#             # Numerical inversion\n",
    "#             δ_1 = δ_0 .+ log.(s) .- log.(sHat(δ=δ_0, X=X, σ=σ, ζ=ζ, I_n=I_n))\n",
    "\n",
    "#             # Max distance in δ\n",
    "#             δ_diff = maximum(abs.(δ_1 - δ_0))\n",
    "\n",
    "#             # Track iterations and update Lipschitz constant every 50 iters\n",
    "#             iter = iter + 1\n",
    "#             if ((iter + 2) % 50) == 0\n",
    "#                   δ_diff_h[1] = Real(δ_diff)\n",
    "#             end\n",
    "#             if ((iter + 1) % 50) == 0\n",
    "#                   δ_diff_h[2] = Real(δ_diff)\n",
    "#             end\n",
    "#             if (iter % 50) == 0\n",
    "#                   δ_diff_h[3] = Real(δ_diff)\n",
    "#                   L = (δ_diff_h[2]^2) / (δ_diff_h[3] * δ_diff_h[1])\n",
    "#                   if output==true\n",
    "#                         println(\"Iteration  \" * string(iter) *\n",
    "#                               \"    Contraction term L is \" * string(L))\n",
    "#                   end\n",
    "#             end\n",
    "#             δ_0 = δ_1\n",
    "#       end\n",
    "\n",
    "#       return δ_0\n",
    "# end\n",
    "\n",
    "\n",
    "# Contraction mapping function\n",
    "function s_contraction_map(;s, X, I_n, σ, ζ, J, ϵ_contract = 1.0e-5, output=false)\n",
    "      δ_0 = convert.(Real, zeros(length(s)))\n",
    "      iter = 0 # Initialize iteration count\n",
    "      δ_diff = 0.5 # Initialize difference in δ (in case L misbehaves)\n",
    "      δ_diff_h = Array{Real}(undef, 1, 3)\n",
    "      while (δ_diff > ϵ_contract) \n",
    "            # Numerical inversion\n",
    "            δ_1 = δ_0 .+ log.(s) .- log.(sHat(δ=δ_0, X=X, σ=σ, ζ=ζ, I_n=I_n))\n",
    "\n",
    "            # Max distance in δ\n",
    "            δ_diff = maximum(abs.(δ_1 - δ_0))\n",
    "\n",
    "            if (iter % 50) == 0 && output==true\n",
    "                println(\"Iteration  \" * string(iter) * \"    Difference is \" * string(δ_diff))\n",
    "            end\n",
    "            δ_0 = δ_1\n",
    "      end\n",
    "\n",
    "      return δ_0\n",
    "end\n",
    "\n",
    "\n",
    "# Log shares Jacobian function - vectorized\n",
    "function log_s_Jac(; ŝ_i, I_n=1, J)\n",
    "      ∫ŝ_j_mat = repeat(1/(I_n) .* sum(ŝ_i, dims=1), outer=J)'\n",
    "      own_term = 1.0/(I_n) * ŝ_i' * (Ref(1.0) .- ŝ_i) .* Matrix(I, J, J)\n",
    "      cross_term = -1.0/(I_n) * (ŝ_i' * ŝ_i) .* (Ref(1.0) .- Matrix(I, J, J))\n",
    "      return (own_term .+ cross_term) ./ ∫ŝ_j_mat\n",
    "end\n",
    "\n",
    "\n",
    "# Newton's method function\n",
    "function s_newton_fxp(; s, δ_0, X, I_n, σ, ζ, J, ϵ_conv=1.0e-14, output=false, maxiter = 1e5)\n",
    "    diff = 0.5\n",
    "    iter = 0 # Initialize iteration count\n",
    "    while diff > ϵ_conv && iter < maxiter\n",
    "        # Compute\n",
    "        ŝ_i = sHat_ind(δ=δ_0, X=X, σ=σ, ζ=ζ, I_n=I_n)\n",
    "        ŝ = sHat_from_ŝ(ŝ_i=ŝ_i, I_n=I_n)\n",
    "        log_sJ = log_s_Jac(ŝ_i=ŝ_i, I_n=I_n, J=J)\n",
    "        log_s = log.(ŝ)\n",
    "        δ_1 = δ_0 .- inv(log_sJ) * (log_s - log.(s))\n",
    "\n",
    "        # Check difference and iterate\n",
    "        diff = maximum(abs.(δ_1 .- δ_0))\n",
    "        iter = iter + 1\n",
    "        if output==true\n",
    "              println(\"Iteration  \" * string(iter) *\n",
    "                    \"    Difference is \" * string(diff))\n",
    "        end\n",
    "        δ_0 = δ_1\n",
    "    end\n",
    "\n",
    "    return δ_0\n",
    "end\n",
    "\n",
    "\n",
    "# Combine two methods function\n",
    "function invert_s(; s, X, I_n, σ, ζ, J, ϵ_contract=1.0e-5, ϵ_conv=1.0e-14, output=false, maxiter_newton = 1e5)\n",
    "    δ_contraction = s_contraction_map(s=s, X=X, I_n=I_n, σ=σ, ζ=ζ, J=J, ϵ_contract=ϵ_contract, output=output)\n",
    "    δ = s_newton_fxp(s=s, δ_0=δ_contraction, X=X, I_n=I_n, σ=σ, ζ=ζ, J=J, ϵ_conv=ϵ_conv, output=output, \n",
    "            maxiter = maxiter_newton)\n",
    "    return δ\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test functions with data from market 17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_17 = 25;\n",
    "X_17 = convert(Matrix, d17[:, [:Price, :Constant, :EngineSize, :SportsBike, :Brand2, :Brand3]]);\n",
    "Z_17 = convert(Matrix, d17[:, [:z1, :z2, :z3, :z4]]);\n",
    "σ_17 = zeros(size(X_17)[2])';\n",
    "ζ_17 = reshape(rand(Normal(0,1),length(σ_17)*I_17), I_17, length(σ_17));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7-element Array{Float64,1}:\n",
       "  2.0697845385676574\n",
       " -0.3439439517828262\n",
       " -2.9273567831528453\n",
       "  0.6068451864947533\n",
       "  3.141160653013621\n",
       "  1.3883038447921399\n",
       "  2.3472954727255972"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test contraction\n",
    "δ_contract = s_contraction_map(s=d17.shares, X=X_17, I_n=I_17, σ=σ_17, ζ=ζ_17, J=size(X_17)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7-element Array{Float64,1}:\n",
       "  2.070264979033944\n",
       " -0.34346351131653924\n",
       " -2.9268763426865583\n",
       "  0.6073256269610395\n",
       "  3.1416410934799073\n",
       "  1.3887842852584265\n",
       "  2.3477759131918825"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Newton's method\n",
    "s_newton_fxp(s=d17.shares, δ_0 = δ_contract, X=X_17, I_n=I_17, σ=σ_17, ζ=ζ_17, J=size(X_17)[1], ϵ_conv=1.0e-14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTRACTION EPSILON IS LARGE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7-element Array{Float64,1}:\n",
       "  2.070264979033939\n",
       " -0.34346351131654446\n",
       " -2.926876342686563\n",
       "  0.6073256269610349\n",
       "  3.1416410934799024\n",
       "  1.3887842852584218\n",
       "  2.347775913191879"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test both\n",
    "invert_s(s=d17.shares, X=X_17, I_n=I_17, σ=σ_17, ζ=ζ_17, J=size(X_17)[1], ϵ_contract=1.0e-4, ϵ_conv=1.0e-14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test with data from the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0]\n",
      "[38.46485052094403, 18.464850520944033, 18.464850520944033]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.00016785577094455723, -0.029659081493348612, -0.012089398619323165]\n",
      "[-0.0611761787212328, -0.0611761787212328, -0.14113460280480175]\n"
     ]
    }
   ],
   "source": [
    "println(invert_s(s=shares_q9[1], σ=σ_q9[2], X=0.0, I_n=1, ζ=0.0, J=J_q9[1]))\n",
    "println(invert_s(s=shares_q9[2], σ=σ_q9[2], X=0.0, I_n=1, ζ=0.0, J=J_q9[2], ϵ_contract=1.0e-4))\n",
    "println(invert_s(s=shares_q9[3], σ=σ_q9[3], X=X_q9[3][1], I_n=I_q9[3], ζ=ζ_q9[3], J=J_q9[3]))\n",
    "println(invert_s(s=shares_q9[3], σ=σ_q9[3], X=X_q9[3][2], I_n=I_q9[3], ζ=ζ_q9[3], J=J_q9[3]))\n",
    "println(invert_s(s=shares_q9[3], σ=σ_q9[3], X=X_q9[3][3], I_n=I_q9[3], ζ=ζ_q9[3], J=J_q9[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/><br/>\n",
    "\n",
    "## Question 11\n",
    "\n",
    "#### Write function for computing $\\xi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ξ_rclogit (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implicit function for ξ - all markets (X_all is vector of matrices)\n",
    "function ξ_rclogit(; X_all, θ, s_all, ζ=0.0, I_num=1, maxiter_newton=1e5, rclogit_output=false)\n",
    "    # θ split between linear terms (1) and nonlinear terms (2)\n",
    "    αβ = θ[1] # Put price first for consistency\n",
    "    σ = θ[2]\n",
    "    \n",
    "    # Loop through markets and invert shares\n",
    "    δhat_all = []\n",
    "    for mkt in 1:length(X_all)\n",
    "        if rclogit_output==true\n",
    "            println(\"Market number is \" * string(mkt) * \" of \" * string(length(X_all)))\n",
    "        end\n",
    "        δhat = invert_s(s=s_all[mkt], X=X_all[mkt], I_n=I_num, σ=σ, ζ=ζ, J=length(s_all[mkt]), \n",
    "                    ϵ_contract=1.0e-3, ϵ_conv=1.0e-14, maxiter_newton = maxiter_newton)\n",
    "        push!(δhat_all, δhat)\n",
    "    end\n",
    "    \n",
    "    # Stack data and compute δ_mean\n",
    "    δhat = reduce(vcat, δhat_all)\n",
    "    X_stack = reduce(vcat, X_all)\n",
    "    δ_mean = X_stack * αβ\n",
    "\n",
    "    # Subtract off mean utility to get ξ̂\n",
    "    return δhat .- δ_mean\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write function for splicing data into markets (array of matrices and vectors, for shares and variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mkt_X_s_break (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mkt_X_s_break(; exclude_vec)\n",
    "    X_full_mkt = []\n",
    "    s_full_mkt = []\n",
    "    for mkt in unique(data[[x ∉ exclude_vec for x in data.Market], :Market])\n",
    "        X_mkt = convert(Matrix, data[data.Market .== mkt,\n",
    "                    [:Price, :Constant, :EngineSize, :SportsBike, :Brand2, :Brand3]])\n",
    "        push!(X_full_mkt, X_mkt)\n",
    "        \n",
    "        s_mkt = data[data.Market .== mkt, :shares]\n",
    "        push!(s_full_mkt, s_mkt)\n",
    "    end\n",
    "    return [X_full_mkt, s_full_mkt]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test functions with data from market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test parameters and select data\n",
    "I_test = 40\n",
    "σ_test = zeros(6)\n",
    "ζ_test = reshape(rand(Normal(0,1),length(σ_test)*I_test), I_test, length(σ_test))\n",
    "Z_test = convert(Matrix, data[:, [:z1, :z2, :z3, :z4]])\n",
    "W_test = inv(Z_test' * Z_test);\n",
    "\n",
    "\n",
    "# Test with expanded instrument set\n",
    "X_no_p = reduce(vcat, test_data[1])[:,2:6]\n",
    "Z_full = hcat(X_no_p, Z_test)\n",
    "W_full = inv(Z_full' * Z_full)\n",
    "\n",
    "\n",
    "# Choose data\n",
    "test_data = mkt_X_s_break(exclude_vec = []);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24.965661 seconds (127.18 M allocations: 17.186 GiB, 20.53% gc time)\n"
     ]
    }
   ],
   "source": [
    "# Test functions at θ = 0\n",
    "θ_zeros = [zeros(6), zeros(6)']\n",
    "@time ξ_zeros = ξ_rclogit(X_all=test_data[1], θ=θ_zeros, s_all=test_data[2], ζ=ζ_test, I_num=I_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Array{Float64,1}:\n",
       "  3.417557706918591\n",
       "  2.2199898323356098\n",
       " -2.8348206236877678\n",
       "  4.317272874619474\n",
       "  1.459620984134135\n",
       "  1.0254328494996232\n",
       "  1.5368650848736685\n",
       " -2.7318744786927707"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ξ_zeros[1:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write GMM objective function using implicit function $\\xi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252.59328031304517"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function f_gmm_rclogit_implθ(; W=I, Z, X_all, θ, s_all, ζ, I_num)\n",
    "    ξ = ξ_rclogit(X_all=X_all, θ=θ, s_all=s_all, ζ=ζ, I_num=I_num)\n",
    "    return (Z' * ξ)' * W * (Z' * ξ)\n",
    "end\n",
    "\n",
    "# Test objective function - computing ξ within (only z1-z4)\n",
    "f_gmm_rclogit_implθ(W=W_test, Z=Z_test, X_all=test_data[1], θ=[zeros(6), zeros(6)'], s_all=test_data[2], \n",
    "    ζ=ζ_test, I_num=I_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2947.137997931572"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test objective function - computing ξ within (using full instruments, including characteristics)\n",
    "f_gmm_rclogit_implθ(W=W_full, Z=Z_full, X_all=test_data[1], θ=[zeros(6), zeros(6)'], s_all=test_data[2], \n",
    "    ζ=ζ_test, I_num=I_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rewrite objective function as a function of only $\\sigma$ (no linear terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f_gmm_rclogit_σ (generic function with 1 method)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for computing linear parameters\n",
    "function θ_tsls(; X, Z, W, δ)\n",
    "    B = X' * Z * W * Z'\n",
    "    return inv(B * X) * (B * δ)\n",
    "end\n",
    "\n",
    "\n",
    "# Function returning ξ(σ), δ(σ), and θ̄(σ)\n",
    "function ξδθ_σ_rclogit(; X_all, σ, s_all, ζ=0.0, I_num=1, Z, W)\n",
    "    δ = []\n",
    "    for mkt in 1:length(X_all)\n",
    "        δ_mkt = invert_s(s=s_all[mkt], X=X_all[mkt], I_n=I_num, σ=σ, ζ=ζ, J=length(s_all[mkt]))\n",
    "        push!(δ, δ_mkt)\n",
    "    end\n",
    "    δ_σ_stack = reduce(vcat, δ)\n",
    "    X_stack = reduce(vcat, X_all)\n",
    "\n",
    "    αβ = θ_tsls(X=X_stack, Z=Z, W=W, δ=δ_σ_stack)\n",
    "    \n",
    "    ξ_all = []\n",
    "    for mkt in 1:length(X_all)\n",
    "        ξ_mkt = δ[mkt] .- X_all[mkt] * αβ\n",
    "        push!(ξ_all, ξ_mkt)\n",
    "    end\n",
    "    ξ = reduce(vcat, ξ_all)\n",
    "    \n",
    "    return (ξ = ξ, δ_all = δ, αβ = αβ, ξ_all = ξ_all)\n",
    "end\n",
    "\n",
    "\n",
    "# Rewrite objective function as only a function of σ\n",
    "function f_gmm_rclogit_σ(;W, Z, X_all, σ, s_all, ζ, I_num)\n",
    "    output = ξδθ_σ_rclogit(X_all=X_all, σ=σ, s_all=s_all, ζ=ζ, I_num=I_num, Z=Z, W=W)\n",
    "    ξ = output.ξ\n",
    "    # println(output.αβ)\n",
    "    return (Z' * ξ)' * W * (Z' * ξ)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.878411530341467"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test objective function at σ=0\n",
    "f_gmm_rclogit_σ(W=W_test, Z=Z_test, X_all=test_data[1], σ=zeros(6)', s_all=test_data[2], ζ=ζ_test, \n",
    "    I_num=I_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/>\n",
    "#### The objective. Let’s get values for markets t = 1 and t = 17, with sigma = 0, and Z is all the market Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002350557910935882"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test objective function at σ=0 (only market 1)\n",
    "f_gmm_rclogit_σ(W=inv(Z_test' * Z_test), Z=convert(Matrix, data[data.Market.==1, [:z1, :z2, :z3, :z4]]), \n",
    "    X_all=[test_data[1][1]], σ=zeros(6)', \n",
    "    s_all=[test_data[2][1]], ζ=ζ_test, I_num=I_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28.036022 seconds (167.65 M allocations: 25.109 GiB, 20.46% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7241370155056548"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time f_gmm_rclogit_σ(W=W_full, Z=Z_full, X_all=test_data[1], σ=zeros(6)', s_all=test_data[2], \n",
    "    ζ=ζ_test, I_num=I_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/><br/>\n",
    "\n",
    "## Question 12\n",
    "\n",
    "#### Write gradient function (as a function of $\\sigma$ only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ξδθ_σ_rclogit(X_all=test_data[1], σ=zeros(6)', s_all=test_data[2], ζ=ζ_test, I_num=I_test,\n",
    "    Z=Z_test, W=W_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "shat_test = sHat_ind_αβ(αβ = output.αβ, X=test_data[1][1], ξ=output.ξ_all[1], σ=ones(6)',\n",
    "    ζ=ζ_test, I_n=I_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ξ_Jac (generic function with 1 method)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Individual share predictor function (given X and αβ)\n",
    "function sHat_ind_αβ(; αβ, X, ξ, σ, ζ=0.0, I_n=1)\n",
    "    # Construct numerators\n",
    "    δ = X * αβ .+ ξ\n",
    "    const_term = repeat(δ', outer=I_n)\n",
    "    rc_term = ζ * (X .* repeat(σ, outer=length(δ)))'\n",
    "    exp_term = const_term .+ rc_term\n",
    "    num = exp.(exp_term)\n",
    "\n",
    "    # Construct denominators and shares\n",
    "    denom = repeat(Ref(1.0) .+ sum(num, dims=2), inner=(1,length(δ)))\n",
    "    ŝ_i = num ./ denom\n",
    "    return ŝ_i\n",
    "end\n",
    "\n",
    "\n",
    "# Function to compute Jacobian of ξ(θ) for each market\n",
    "function ξ_Jac_θ_mkt(; X, I_n, ζ, ŝ_i)\n",
    "    ξ_J = zeros(size(X)[1], size(X)[1])\n",
    "    J_σ = zeros(size(X)[1], size(X)[2])\n",
    "    for i in 1:I_n\n",
    "        s = ŝ_i[i,:]\n",
    "        ξ_Ji = -1.0 * ((s * s') .- diagm(vec(s)))\n",
    "        ξ_J = ξ_J .+ (1/I_n) .* ξ_Ji\n",
    "        J_σ = J_σ .+ (ξ_Ji * X) * diagm(ζ[i,:])\n",
    "    end\n",
    "    return -1.0 * inv(ξ_J) * J_σ./I_n\n",
    "end\n",
    "\n",
    "\n",
    "# Function for computing Jacobian of ξ(θ) for all markets\n",
    "function ξ_Jac(; X_all, αβ, I_n, ζ, σ, ξ_all)\n",
    "      ξ_J_θ = []\n",
    "      for mkt in 1:length(X_all)\n",
    "            X_mkt = X_all[mkt];\n",
    "            ŝ_i = sHat_ind_αβ(αβ=αβ, X=X_mkt, ξ=ξ_all[mkt], σ=σ, ζ=ζ, I_n=I_n)\n",
    "            ξ_J_θ_mkt = ξ_Jac_θ_mkt(X=X_mkt, I_n=I_n, ζ=ζ, ŝ_i=ŝ_i)\n",
    "            push!(ξ_J_θ, ξ_J_θ_mkt)\n",
    "      end\n",
    "      ξ_J = reduce(vcat, ξ_J_θ)\n",
    "      return ξ_J\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write functions that compute analytic gradient (and objective function as a function of $\\sigma$ only, for comparison with ForwardDiff)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmm_σ_test (generic function with 1 method)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function that computes gradient given σ and only σ\n",
    "function f_gmm_rclogit_σ_g(; X_all, s_all, Z, W, σ, I_n, ζ)\n",
    "    ξδθ_output =  ξδθ_σ_rclogit(X_all=X_all, σ=σ, s_all=s_all, ζ=ζ, I_num=I_n, Z=Z, W=W);\n",
    "    ξ_J = ξ_Jac(X_all=X_all, αβ=ξδθ_output.αβ, I_n=I_n, ζ=ζ, σ=σ, ξ_all=ξδθ_output.ξ_all)\n",
    "    df_θ = 2 * (Z' * ξ_J)' * W * (Z' * ξδθ_output.ξ)\n",
    "    return df_θ\n",
    "end\n",
    "\n",
    "# Function that computes objective function for given σ, using full data\n",
    "function gmm_σ_test_full(σ_init) \n",
    "    func = f_gmm_rclogit_σ(W=W_full, Z=Z_full, X_all=test_data[1], σ=σ_init,\n",
    "                        s_all=test_data[2], ζ=ζ_test, I_num=I_test)\n",
    "    return func\n",
    "end\n",
    "\n",
    "# Function that computes objective function for given σ, using \"test\" data\n",
    "function gmm_σ_test(σ_init) \n",
    "    func = f_gmm_rclogit_σ(W=W_test, Z=Z_test, X_all=test_data[1], σ=σ_init,\n",
    "                        s_all=test_data[2], ζ=ζ_test, I_num=I_test)\n",
    "    return func\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare auto-differentiation with analytic gradients.\n",
    "\n",
    "##### Using z1-z4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " -282.907  20.6999  -537.221  -22.84  3.7184  -28.162"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analytic\n",
    "f_gmm_rclogit_σ_g(X_all=test_data[1], s_all=test_data[2], Z=Z_test, W=W_test, \n",
    "    σ=zeros(6)', I_n=I_test, ζ=ζ_test)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " 0.957584  18.7794  34.0614  0.501048  -0.295995  -0.16443"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Auto-diff\n",
    "ForwardDiff.gradient(gmm_σ_test, zeros(6)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At 0.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " -259.388  101.306  917.877  -23.2381  -14.3924  -90.4662"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analytic\n",
    "f_gmm_rclogit_σ_g(X_all=test_data[1], s_all=test_data[2], Z=Z_test, W=W_test, \n",
    "    σ=0.1*ones(6)', I_n=I_test, ζ=ζ_test)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " 61.257  -5.28611  453.086  12.2696  -5.54666  -0.864887"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Auto-diff\n",
    "ForwardDiff.gradient(gmm_σ_test, 0.1*ones(6)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using expanded instrument set:\n",
    "\n",
    "At 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " -2.06635e-12  -2.27511e-12  1.49341e-11  …  -1.44035e-13  1.96688e-12"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analytic\n",
    "f_gmm_rclogit_σ_g(X_all=test_data[1], s_all=test_data[2], Z=Z_full, W=W_full, \n",
    "    σ=zeros(6)', I_n=I_test, ζ=ζ_test)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " -6.15277e-15  -5.13637e-15  3.93809e-14  …  2.09548e-15  -3.40415e-15"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Auto-diff\n",
    "ForwardDiff.gradient(gmm_σ_test_full, zeros(6)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At 0.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " 0.142389  0.0297017  1.24713  0.0441153  0.144087  0.20602"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analytic\n",
    "f_gmm_rclogit_σ_g(X_all=test_data[1], s_all=test_data[2], Z=Z_full, W=W_full, \n",
    "    σ=0.1*ones(6)', I_n=I_test, ζ=ζ_test)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Adjoint{Float64,Array{Float64,1}}:\n",
       " 0.142389  0.0297017  1.24713  0.0441153  0.144087  0.20602"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Auto-diff\n",
    "ForwardDiff.gradient(gmm_σ_test_full, 0.1*ones(6)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/><br/>\n",
    "\n",
    "## Question 13\n",
    "\n",
    "#### Write GMM function that only takes in the desired values of $\\sigma$ (for random coefficients on price and engine size).\n",
    "\n",
    "##### GMM function using only z1-z4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmm_σ (generic function with 1 method)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gmm_σ(σ_init) \n",
    "    σ_mod = [σ_init[1], 0, σ_init[2], 0, 0, 0]' # Only price and engine size have RCs\n",
    "    func = f_gmm_rclogit_σ(W=W_test, Z=Z_test, X_all=test_data[1], σ=σ_mod,\n",
    "                        s_all=test_data[2], ζ=ζ_test, I_num=I_test)\n",
    "    return func\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9382951920911218"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test GMM function\n",
    "gmm_σ(0.1*ones(2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmm_σ_g (generic function with 1 method)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gmm_σ_g(σ_init) \n",
    "    σ_mod = [σ_init[1], 0, σ_init[2], 0, 0, 0]' # Only price and engine size have RCs\n",
    "    grad = f_gmm_rclogit_σ_g(X_all=test_data[1], s_all=test_data[2], Z=Z_test, W=W_test, \n",
    "                    σ=σ_mod, I_n=I_test, ζ=ζ_test)'\n",
    "    return grad[[1,3]]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       "   66.42296148132766\n",
       " -233.03681165127614"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_σ_g(0.1*ones(2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GMM function using full sets of instruments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmm_σ_full (generic function with 1 method)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gmm_σ_full(σ_init) \n",
    "    σ_mod = [σ_init[1], 0, σ_init[2], 0, 0, 0]' # Only price and engine size have RCs\n",
    "    func = f_gmm_rclogit_σ(W=W_full, Z=Z_full, X_all=test_data[1], σ=σ_mod,\n",
    "                        s_all=test_data[2], ζ=ζ_test, I_num=I_test)\n",
    "    return func\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.772801277628305"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test GMM function\n",
    "gmm_σ_full(0.1*ones(2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmm_σ_full_g (generic function with 1 method)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gmm_σ_full_g(σ_init) \n",
    "    σ_mod = [σ_init[1], 0, σ_init[2], 0, 0, 0]' # Only price and engine size have RCs\n",
    "    grad = f_gmm_rclogit_σ_g(X_all=test_data[1], s_all=test_data[2], Z=Z_full, W=W_full, \n",
    "                σ=σ_mod, I_n=I_test, ζ=ζ_test)'\n",
    "    return grad[[1,3]]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.14995226877601997\n",
       " 1.0197988287607602"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_σ_full_g(0.1*ones(2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One more sanity check to make sure the gradients match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×2 Adjoint{Float64,Array{Float64,1}}:\n",
       " 0.149952  1.0198"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct auto-diff function as placeholder\n",
    "g_gmm_σ_auto_full = x -> ForwardDiff.gradient(gmm_σ_full, x)\n",
    "g_gmm_σ_auto_full(0.1 * ones(2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write function for calling one stage of GMM for a given weighting matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmm_stage (generic function with 1 method)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gmm_stage(; W, Z, X_all, s_all, ζ, I_num, σ_init)\n",
    "    # Objective function\n",
    "    function f_obj(σ_init) \n",
    "        σ_mod = [σ_init[1], 0, σ_init[2], 0, 0, 0]' # Only price and engine size have RCs\n",
    "        func = f_gmm_rclogit_σ(W=W, Z=Z, X_all=X_all, σ=σ_mod, s_all=s_all, ζ=ζ, I_num=I_num)\n",
    "        return func\n",
    "    end\n",
    "    \n",
    "    # Gradient function\n",
    "    function g_obj(G, σ_init)\n",
    "        grad = gmm_σ_full_g(σ_init)\n",
    "        G[1:2] = grad\n",
    "    end\n",
    "    \n",
    "#     # AD gradient function - for testing Optim and comparison with coded gradient function\n",
    "#     g_gmm_σ_auto_test = x -> ForwardDiff.gradient(f_obj, x)\n",
    "#     function g_obj(G, σ_init)\n",
    "#         grad = g_gmm_σ_auto_test(σ_init)\n",
    "#         G[1:2] = grad[1:2]\n",
    "#     end\n",
    "    \n",
    "    # Return result\n",
    "    σ_result = Optim.minimizer(optimize(f_obj, g_obj, σ_init, BFGS(), Optim.Options(show_trace=true)))\n",
    "    return σ_result\n",
    "end  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter     Function value   Gradient norm \n",
      "     0     7.760773e-01     1.019799e+00\n",
      " * time: 0.0031409263610839844\n",
      "     1     7.567699e-01     7.298156e-01\n",
      " * time: 32.961628913879395\n",
      "     2     7.261348e-01     1.434374e-01\n",
      " * time: 117.93993782997131\n",
      "     3     7.241460e-01     8.346210e-03\n",
      " * time: 162.37639093399048\n",
      "     4     7.241370e-01     3.220799e-04\n",
      " * time: 238.96201491355896\n",
      "     5     7.241370e-01     7.185621e-07\n",
      " * time: 286.306275844574\n",
      "     6     7.241370e-01     5.592656e-11\n",
      " * time: 366.7638268470764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " -2.026765828312821e-11\n",
       "  7.808585295611604e-12"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_stage(W=W_full, Z=Z_full, X_all=test_data[1], s_all=test_data[2], ζ=ζ_test, I_num=I_test, \n",
    "    σ_init=0.1*ones(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gmm_stage(W=W_full, Z=Z_full, X_all=test_data[1], s_all=test_data[2], ζ=ζ_test, I_num=I_test, \n",
    "#     σ_init=0.5*ones(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "step_size (generic function with 1 method)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose step size\n",
    "function step_size(; x_1, x_0, g_1, g_0)\n",
    "    # x's are columns (so transpose is row), g's are columns\n",
    "    num = (x_1 .- x_0) * (g_1 .- g_0)'\n",
    "    denom = (g_1[1] - g_0[1])^2 + (g_1[2] - g_0[2])^2\n",
    "    return abs((num / denom)[1])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "descent (generic function with 1 method)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient descent function\n",
    "function descent(; σ, start_step, ϵ_conv)\n",
    "    \n",
    "    # Gradient\n",
    "    g_0 = gmm_σ_full_g(σ) \n",
    "    \n",
    "    # Prepare for iterating\n",
    "    step = start_step; iter = 0\n",
    "    x_0 = σ\n",
    "    x_1 = x_0 .- start_step * g_0\n",
    "    g_1 = gmm_σ_full_g(x_1) \n",
    "    \n",
    "    println(g_1)\n",
    "    println(g_0)\n",
    "    \n",
    "    # Value of objective\n",
    "    obj = gmm_σ_full(x_1) \n",
    "    println(\"Iteration is \" * string(iter) * \"    Objective function is \" * string(obj))\n",
    "    println(\"   Step size was \" * string(step))\n",
    "    println(\"   Parameter values are \" * string(x_1))\n",
    "    \n",
    "    # Iterate\n",
    "    while abs(step) > ϵ_conv\n",
    "        step = step_size(x_1=x_1, x_0=x_0, g_1=g_1, g_0=g_0)\n",
    "        if step != NaN\n",
    "            x_new = x_1 .- step * g_1\n",
    "            g_new = gmm_σ_full_g(x_1)\n",
    "\n",
    "            # Update\n",
    "            x_0 = copy(x_1); x_1 = copy(x_new);\n",
    "            g_0 = copy(g_1); g_1 = copy(g_new);\n",
    "            println(g_new)\n",
    "            println(g_1)\n",
    "            println(g_0)\n",
    "\n",
    "            iter = iter + 1\n",
    "            obj = gmm_σ_full(x_1) \n",
    "            println(\"Iteration is \" * string(iter) * \"    Objective function is \" * string(obj))\n",
    "            println(\"   Step size was \" * string(step))\n",
    "            println(\"   Parameter values are \" * string(x_1))\n",
    "        else\n",
    "            step = ϵ_conv/2\n",
    "        end\n",
    "    end\n",
    "    return (σ=x_1, obj_val=obj)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6355103430904085, -17.419294425540144]\n",
      "[-0.1585550891091021, 19.614250024137906]\n",
      "Iteration is 0    Objective function is 4.091711214330781\n",
      "   Step size was 0.05\n",
      "   Parameter values are [0.5079277544554551, -0.48071250120689535]\n",
      "[1.6355103430904085, -17.419294425540144]\n",
      "[1.6355103430904085, -17.419294425540144]\n",
      "[1.6355103430904085, -17.419294425540144]\n",
      "Iteration is 1    Objective function is 4.08854513735258\n",
      "   Step size was 1.0346176364886647e-5\n",
      "   Parameter values are [0.5079108331769989, -0.48053227811461685]\n",
      "[1.6358417854405882, -17.408642813349292]\n",
      "[1.6358417854405882, -17.408642813349292]\n",
      "[1.6355103430904085, -17.419294425540144]\n",
      "Iteration is 2    Objective function is NaN\n",
      "   Step size was NaN\n",
      "   Parameter values are [NaN, NaN]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(σ = [NaN, NaN], obj_val = NaN)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = descent(σ=0.5*ones(2), start_step=0.05, ϵ_conv=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×2 Adjoint{Float64,Array{Float64,1}}:\n",
       " -1.0  -1.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(zeros(2) .- ones(2))'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write functions for implementing two-stage GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for optimal weighting matrix\n",
    "function gmm_opt_weight(; Z, ξ)\n",
    "    n = size(Z)[1]\n",
    "    Zξ = Z' * ξ\n",
    "    return inv((1/n) * Zξ * Zξ')\n",
    "end\n",
    "\n",
    "\n",
    "# Function for gradient of ξ with respect to all parameters - STILL NEED TO FINISH THIS!!!!!!!!!!!!!!!!!!!!!!!\n",
    "function ZJ_θfull_J(; Z, ξ, X_all, αβ, I_n, ζ, σ)\n",
    "    n = size(Z)[1]\n",
    "    Jac_αβ = reduce(vcat, X_all)\n",
    "    Jac_σ = ξ_Jac(X_all=X_all, αβ=αβ, I_n=I_n, ζ=ζ, σ=σ)\n",
    "    Jac_θ = hcat(Jac_αβ, Jac_σ)\n",
    "    return -(1/n) * Z' * Jac_θ\n",
    "end\n",
    "\n",
    "\n",
    "# Function for two-stage GMM\n",
    "function two_stage_gmm(; W_stage1, Z, X_all, s_all, ζ, I_num, σ_init)\n",
    "    # First stage estimation with given starting weighting matrix\n",
    "    σ_stage1 = gmm_stage(W=W_stage1, Z=Z, X_all=X_all, s_all=s_all, ζ=ζ, I_num=I_num, σ_init=σ_init)\n",
    "    \n",
    "    # Compute optimal weighting matrix for second stage\n",
    "    ξδθ_output =  ξδθ_σ_rclogit(X_all=X_all, σ=σ_stage1, s_all=s_all, ζ=ζ, I_num=I_num, Z=Z, W=W_stage1)\n",
    "    ξ_stage1 = ξδθ_output.ξ\n",
    "    W_stage2 = gmm_opt_weight(Z=Z, ξ=ξ_stage1)\n",
    "    \n",
    "    # Second stage estimation with given starting weighting matrix\n",
    "    σ_stage2 = gmm_stage(W=W_stage2, Z=Z, X_all=X_all, s_all=s_all, ζ=ζ, I_num=I_num, σ_init=σ_stage1)\n",
    "    \n",
    "    # Compute covariance matrix for point estimates\n",
    "    ξδθ_output =  ξδθ_σ_rclogit(X_all=X_all, σ=σ_stage2, s_all=s_all, ζ=ζ, I_num=I_num, Z=Z, W=W_stage2)\n",
    "    G = ZJ_θfull_J(Z=Z, ξ=.ξδθ_outputξ, X_all=X_all, αβ=ξδθ_output.αβ, I_n=I_num, ζ=ζ, σ=σ)\n",
    "    ξ_stage1 = ξδθ_output.ξ\n",
    "    W_stage2 = gmm_opt_weight(Z=Z, ξ=ξ_stage1)\n",
    "    Σ = inv(G' * inv(W_stage2) * G)\n",
    "    \n",
    "    # Return values\n",
    "    return (σ = σ_stage2, αβ = ξδθ_output.αβ, Σ = Σ)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/><br/><br/><br/>\n",
    "\n",
    "## Question 14\n",
    "\n",
    "##### Use PyBLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <module 'os' from '/Users/JoshuaHigbee/.julia/conda/3/lib/python3.8/os.py'>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyblp = pyimport(\"pyblp\")\n",
    "np = pyimport(\"numpy\")\n",
    "pd = pyimport(\"pandas\")\n",
    "os = pyimport(\"os\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/JoshuaHigbee/Box/2. Second Year/2. Winter Quarter - 2021/Industrial Organization II - Hortacsu/Problem Sets/Problem Set 1\""
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Market</th>\n",
       "      <th>Constant</th>\n",
       "      <th>Price</th>\n",
       "      <th>EngineSize</th>\n",
       "      <th>SportsBike</th>\n",
       "      <th>Brand2</th>\n",
       "      <th>Brand3</th>\n",
       "      <th>z1</th>\n",
       "      <th>z2</th>\n",
       "      <th>z3</th>\n",
       "      <th>z4</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.554708</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.237685</td>\n",
       "      <td>0.063116</td>\n",
       "      <td>0.034361</td>\n",
       "      <td>0.056459</td>\n",
       "      <td>0.239077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.559811</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.186073</td>\n",
       "      <td>0.326445</td>\n",
       "      <td>0.062091</td>\n",
       "      <td>0.072184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.857186</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164550</td>\n",
       "      <td>0.033308</td>\n",
       "      <td>0.075316</td>\n",
       "      <td>0.278736</td>\n",
       "      <td>0.000460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.995438</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.485538</td>\n",
       "      <td>0.117025</td>\n",
       "      <td>0.345850</td>\n",
       "      <td>0.084891</td>\n",
       "      <td>0.587867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.017987</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582503</td>\n",
       "      <td>0.368032</td>\n",
       "      <td>0.652134</td>\n",
       "      <td>0.509693</td>\n",
       "      <td>0.033746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>2.010710</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.257544</td>\n",
       "      <td>0.068546</td>\n",
       "      <td>0.095527</td>\n",
       "      <td>0.185333</td>\n",
       "      <td>0.000548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>2.001591</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042531</td>\n",
       "      <td>0.474048</td>\n",
       "      <td>0.285886</td>\n",
       "      <td>0.263406</td>\n",
       "      <td>0.024166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1.692977</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021038</td>\n",
       "      <td>0.453095</td>\n",
       "      <td>0.079379</td>\n",
       "      <td>0.276368</td>\n",
       "      <td>0.355868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>2.337965</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.565742</td>\n",
       "      <td>0.190674</td>\n",
       "      <td>0.695795</td>\n",
       "      <td>0.044509</td>\n",
       "      <td>0.347937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>4.683845</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.474889</td>\n",
       "      <td>0.348956</td>\n",
       "      <td>0.225896</td>\n",
       "      <td>0.692309</td>\n",
       "      <td>0.008260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1047 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "PyObject       Market  Constant     Price  ...        z3        z4    shares\n",
       "0          1         1  1.554708  ...  0.034361  0.056459  0.239077\n",
       "1          1         1  1.559811  ...  0.326445  0.062091  0.072184\n",
       "2          1         1  1.857186  ...  0.075316  0.278736  0.000460\n",
       "3          1         1  1.995438  ...  0.345850  0.084891  0.587867\n",
       "4          1         1  4.017987  ...  0.652134  0.509693  0.033746\n",
       "...      ...       ...       ...  ...       ...       ...       ...\n",
       "1042     150         1  2.010710  ...  0.095527  0.185333  0.000548\n",
       "1043     150         1  2.001591  ...  0.285886  0.263406  0.024166\n",
       "1044     150         1  1.692977  ...  0.079379  0.276368  0.355868\n",
       "1045     150         1  2.337965  ...  0.695795  0.044509  0.347937\n",
       "1046     150         1  4.683845  ...  0.225896  0.692309  0.008260\n",
       "\n",
       "[1047 rows x 12 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_data = pd.read_csv(\"psetOne.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data.rename(columns=Dict(\"Price\"=>\"prices\", \"Market\"=>\"market_ids\", \"z1\"=>\"demand_instruments0\",\n",
    "        \"z2\"=>\"demand_instruments1\", \"z3\"=>\"demand_instruments2\", \"z4\"=>\"demand_instruments3\"), inplace=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PyObject 1 + prices + EngineSize + SportsBike + Brand2 + Brand3, PyObject prices + EngineSize)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_formulations = (pyblp.Formulation(\"prices + 1 + EngineSize + SportsBike + Brand2 + Brand3\"),\n",
    "   pyblp.Formulation(\"0 + prices + EngineSize\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject Configured to construct nodes and weights with Monte Carlo simulation with options {seed: 12345}."
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_integration = pyblp.Integration(\"monte_carlo\", size=40, specification_options=Dict(\"seed\"=>12345))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject Dimensions:\n",
       "=================================\n",
       " T    N     I     K1    K2    MD \n",
       "---  ----  ----  ----  ----  ----\n",
       "150  1047  6000   6     2     9  \n",
       "=================================\n",
       "\n",
       "Formulations:\n",
       "=========================================================================================\n",
       "       Column Indices:           0         1           2           3         4       5   \n",
       "-----------------------------  ------  ----------  ----------  ----------  ------  ------\n",
       " X1: Linear Characteristics      1       prices    EngineSize  SportsBike  Brand2  Brand3\n",
       "X2: Nonlinear Characteristics  prices  EngineSize                                        \n",
       "========================================================================================="
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem = pyblp.Problem(product_formulations, product_data, integration=mc_integration, add_exogenous=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject Configured to optimize using the BFGS algorithm implemented in SciPy with analytic gradients and options {gtol: +1.000000E-06}."
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfgs = pyblp.Optimization(\"bfgs\", Dict(\"gtol\"=>1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the problem ...\n",
      "Initialized the problem after 00:00:00.\n",
      "\n",
      "Dimensions:\n",
      "=================================\n",
      " T    N     I     K1    K2    MD \n",
      "---  ----  ----  ----  ----  ----\n",
      "150  1047  6000   6     2     9  \n",
      "=================================\n",
      "\n",
      "Formulations:\n",
      "=========================================================================================\n",
      "       Column Indices:           0         1           2           3         4       5   \n",
      "-----------------------------  ------  ----------  ----------  ----------  ------  ------\n",
      " X1: Linear Characteristics      1       prices    EngineSize  SportsBike  Brand2  Brand3\n",
      "X2: Nonlinear Characteristics  prices  EngineSize                                        \n",
      "=========================================================================================\n",
      "Solving the problem ...\n",
      "\n",
      "Nonlinear Coefficient Initial Values:\n",
      "========================================\n",
      "  Sigma:       prices       EngineSize  \n",
      "----------  -------------  -------------\n",
      "  prices    +1.000000E+00               \n",
      "EngineSize  +0.000000E+00  +1.000000E+00\n",
      "========================================\n",
      "\n",
      "Nonlinear Coefficient Lower Bounds:\n",
      "========================================\n",
      "  Sigma:       prices       EngineSize  \n",
      "----------  -------------  -------------\n",
      "  prices        -INF                    \n",
      "EngineSize  +0.000000E+00      -INF     \n",
      "========================================\n",
      "\n",
      "Nonlinear Coefficient Upper Bounds:\n",
      "========================================\n",
      "  Sigma:       prices       EngineSize  \n",
      "----------  -------------  -------------\n",
      "  prices        +INF                    \n",
      "EngineSize  +0.000000E+00      +INF     \n",
      "========================================\n",
      "\n",
      "Starting optimization ...\n",
      "\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      "GMM   Optimization   Objective   Fixed Point  Contraction  Clipped    Objective      Objective      Gradient                                 \n",
      "Step   Iterations   Evaluations  Iterations   Evaluations  Shares       Value       Improvement       Norm                  Theta            \n",
      "----  ------------  -----------  -----------  -----------  -------  -------------  -------------  -------------  ----------------------------\n",
      " 1         0             1          13634        41099        0     +4.809799E+03                 +2.238605E+04  +1.000000E+00, +1.000000E+00\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         0             2          3861         11710        0     +9.766857E+02  +3.833114E+03  +2.083881E+03  +9.365595E-01, -8.005608E-03\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         1             3          10908        32897        0     +2.774857E+03                 +4.835691E+03  -2.794130E+00, -1.190766E-01\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         1             4          4347         13191        0     +5.768845E+02  +3.998013E+02  +1.346412E+03  -7.486781E-01, -5.817891E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         2             5          2426         7470         0     +4.592300E+02  +1.176545E+02  +3.535607E+02  -1.718172E-01, -1.860329E-02\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         3             6          1724         5355         0     +6.435671E+01  +3.948733E+02  +2.712951E+01  +3.311047E-02, -6.260680E-03\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4             7          1950         6017         4     +1.857572E+38                 +6.674032E+19  +1.992757E-02, -5.415280E-03\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4             8          1724         5355         0     +1.318029E+02                 +2.884672E+01  +3.311047E-02, -6.260680E-03\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4             9          1950         6017         4     +4.478863E+37                 +3.275051E+19  +1.992757E-02, -5.415280E-03\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            10          2341         7200         8     +3.096632E+37                 +2.843325E+19  +2.651902E-02, -5.837980E-03\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            11          1735         5391         0     +1.822571E+02                 +3.545409E+01  +2.981475E-02, -6.049330E-03\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            12          1624         5057         0     +1.568577E+02                 +4.302881E+01  +3.091332E-02, -6.119780E-03\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            13          2161         6661         8     +1.564836E+37                 +2.943248E+19  +3.201190E-02, -6.190230E-03\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            14          2242         6908         8     +2.007664E+38                 +5.248883E+19  +3.256118E-02, -6.225455E-03\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            15          2351         7233         8     +9.289916E+37                 +5.039524E+19  +3.283583E-02, -6.243067E-03\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            16          2315         7128         8     +1.713754E+38                 +3.115270E+19  +3.297315E-02, -6.251874E-03\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            17          2082         6434         4     +2.115847E+38                 +5.354668E+19  +3.304181E-02, -6.256277E-03\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            18          2252         6937         8     +1.426366E+38                 +8.976598E+19  +3.307614E-02, -6.258478E-03\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            19          1966         6076         8     +8.366436E+37                 +3.786012E+19  +3.309331E-02, -6.259579E-03\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 1         4            20          2157         6649         0     +7.941192E+02                 +9.720252E+01  +3.310189E-02, -6.260129E-03\n",
      "\n",
      "The optimization routine failed to converge. This problem can sometimes be mitigated by choosing more reasonable initial parameter values, setting more conservative bounds, or configuring other optimization settings.\n",
      "\n",
      "\n",
      "Optimization failed after 00:00:44.\n",
      "Computing the Hessian and and updating the weighting matrix ...\n",
      "\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      "Computed results after 00:00:08.\n",
      "\n",
      "Problem Results Summary:\n",
      "=============================================================================================\n",
      "GMM     Objective      Gradient         Hessian         Hessian     Clipped  Weighting Matrix\n",
      "Step      Value          Norm       Min Eigenvalue  Max Eigenvalue  Shares   Condition Number\n",
      "----  -------------  -------------  --------------  --------------  -------  ----------------\n",
      " 1    +1.797132E+02  +3.703161E+01  -5.015931E+27   +1.280354E+27      0      +2.317554E+03  \n",
      "=============================================================================================\n",
      "\n",
      "Starting optimization ...\n",
      "\n",
      "GMM   Optimization   Objective   Fixed Point  Contraction  Clipped    Objective      Objective      Gradient                                 \n",
      "Step   Iterations   Evaluations  Iterations   Evaluations  Shares       Value       Improvement       Norm                  Theta            \n",
      "----  ------------  -----------  -----------  -----------  -------  -------------  -------------  -------------  ----------------------------\n",
      " 2         0             1            5           172         0     +1.844190E+01                 +1.651199E+01  +3.311047E-02, -6.260680E-03\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 2         0             2          11056        33360        0     +1.020329E+03                 +7.287342E+03  -5.391271E-01, +8.259918E-01\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 2         0             3          3458         10522        0     +3.621385E+02                 +2.316371E+03  -1.138977E-01, +2.075455E-01\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "Encountered a numerical error when computing delta. This problem is often due to prior problems, overflow, or nonpositive shares, and can sometimes be mitigated by choosing smaller initial parameter values, setting more conservative bounds on parameters or shares, rescaling data, removing outliers, changing the floating point precision, or using different optimization, iteration, or integration configurations. Errors encountered: divide by zero.\n",
      "\n",
      " 2         0             4          1334         4175         0     +1.418489E+02                 +3.038087E+01  +3.238025E-02, -5.198661E-03"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject Problem Results Summary:\n",
       "================================================================================================================\n",
       "GMM     Objective      Gradient         Hessian         Hessian     Clipped  Weighting Matrix  Covariance Matrix\n",
       "Step      Value          Norm       Min Eigenvalue  Max Eigenvalue  Shares   Condition Number  Condition Number \n",
       "----  -------------  -------------  --------------  --------------  -------  ----------------  -----------------\n",
       " 2    +1.136687E+02  +3.525152E+01  -1.230461E+08   +2.091842E+09      0      +2.146586E+03      +3.351864E+04  \n",
       "================================================================================================================\n",
       "\n",
       "Cumulative Statistics:\n",
       "===========================================================================\n",
       "Computation  Optimizer  Optimization   Objective   Fixed Point  Contraction\n",
       "   Time      Converged   Iterations   Evaluations  Iterations   Evaluations\n",
       "-----------  ---------  ------------  -----------  -----------  -----------\n",
       " 00:01:33       No           4            40         120666       368602   \n",
       "===========================================================================\n",
       "\n",
       "Nonlinear Coefficient Estimates (Robust SEs in Parentheses):\n",
       "============================================\n",
       "  Sigma:        prices         EngineSize   \n",
       "----------  ---------------  ---------------\n",
       "  prices     +3.311047E-02                  \n",
       "            (+6.265329E-01)                 \n",
       "                                            \n",
       "EngineSize   +0.000000E+00    -6.260680E-03 \n",
       "                             (+3.500770E-01)\n",
       "============================================\n",
       "\n",
       "Beta Estimates (Robust SEs in Parentheses):\n",
       "====================================================================================================\n",
       "       1             prices         EngineSize       SportsBike         Brand2           Brand3     \n",
       "---------------  ---------------  ---------------  ---------------  ---------------  ---------------\n",
       " +1.293573E+00    -1.969467E+00    +5.882427E-01    +6.240085E-01    -9.345504E-01    +4.286405E-01 \n",
       "     (NAN)       (+7.786234E-02)  (+1.243885E-02)       (NAN)       (+4.464735E-02)  (+7.468087E-02)\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = problem.solve(sigma=np.identity(2), optimization=bfgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×1 Array{Float64,2}:\n",
       "  1.2935728843531908\n",
       " -1.9694667377821897\n",
       "  0.5882426601881855\n",
       "  0.6240084675211102\n",
       " -0.9345504046789983\n",
       "  0.42864047278026596"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "αβ_pyblp = results.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       "  0.03311047248382437\n",
       " -0.0062606797775226"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "σ_pyblp = diag(results.sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/><br/><br/><br/>\n",
    "\n",
    "## Question 15\n",
    "\n",
    "#### Elasticity matrix for market $t=17$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get predicted $\\xi$ from the parameters found earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "σ_pyblp_all = [σ_pyblp[1], 0, σ_pyblp[2], 0, 0, 0]'\n",
    "αβ_pyblp_all = [αβ_pyblp[2], αβ_pyblp[1], αβ_pyblp[3:6]]\n",
    "\n",
    "output = ξδθ_σ_rclogit(X_all=test_data[1], σ=σ_pyblp_all, s_all=test_data[2], ζ=ζ_test, I_num=I_test,\n",
    "    Z=Z_full, W=W_full)\n",
    "\n",
    "ξ_17 = output.ξ_all[17];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "elasticity (generic function with 3 methods)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function elasticity(; αβ, X, σ, ζ, ξ, prices)\n",
    "    # Get necessary numbers\n",
    "    J = size(X,1)\n",
    "    el = zeros(J,J)\n",
    "    n = size(ζ)\n",
    "    \n",
    "    # Predict individual and aggregate shares of each good\n",
    "    ŝ_i = sHat_ind_αβ(αβ=αβ, X=X, ξ=ξ, σ=σ, ζ=ζ, I_n=n)\n",
    "    s_mkt = mean(ŝ_i, dims=2)\n",
    "    \n",
    "    # Vector of individual price coefficients\n",
    "    α_i = Ref(αβ[1]) .+ ζ * σ[1]\n",
    "    \n",
    "    # Fill in elasticity matrix\n",
    "    for j in 1:J\n",
    "        for k in 1:J\n",
    "            if j==k\n",
    "                el[j,k] = - (prices[j]/s_mkt[j]) * mean(α_i .* ŝ_i[i,j]*(1-ŝ_i[i,j]) for i in 1:n)\n",
    "            else\n",
    "                el[j,k] = (prices[k]/s_mkt[j]) * mean(α_i .* ŝ_i[i,j]*ŝ_i[i,k] for i in 1:n)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return el\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "DimensionMismatch(\"arrays could not be broadcast to a common size; got a dimension with lengths 42 and 7\")",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch(\"arrays could not be broadcast to a common size; got a dimension with lengths 42 and 7\")",
      "",
      "Stacktrace:",
      " [1] _bcs1 at ./broadcast.jl:501 [inlined]",
      " [2] _bcs at ./broadcast.jl:495 [inlined] (repeats 2 times)",
      " [3] broadcast_shape at ./broadcast.jl:489 [inlined]",
      " [4] combine_axes at ./broadcast.jl:484 [inlined]",
      " [5] instantiate at ./broadcast.jl:266 [inlined]",
      " [6] materialize at ./broadcast.jl:837 [inlined]",
      " [7] sHat_ind_αβ(; αβ::Array{Float64,2}, X::Array{Float64,2}, ξ::Array{Float64,1}, σ::Adjoint{Float64,Array{Float64,1}}, ζ::Array{Float64,2}, I_n::Tuple{Int64,Int64}) at ./In[99]:7",
      " [8] elasticity(; αβ::Array{Float64,2}, X::Array{Float64,2}, σ::Adjoint{Float64,Array{Float64,1}}, ζ::Array{Float64,2}, ξ::Array{Float64,1}, prices::Array{Float64,1}) at ./In[216]:8",
      " [9] top-level scope at In[218]:1",
      " [10] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "Elast = elasticity(αβ=αβ_pyblp, X=X_17, σ=σ_pyblp_all, ζ=ζ_test, ξ=ξ_17, \n",
    "    prices=X_17[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lap(Elast)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
